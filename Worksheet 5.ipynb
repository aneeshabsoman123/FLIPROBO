{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\91890\\anaconda3\\lib\\site-packages (3.141.0)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\91890\\anaconda3\\lib\\site-packages (from selenium) (1.25.11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.3.3; however, version 21.2.2 is available.\n",
      "You should consider upgrading via the 'c:\\users\\91890\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape the details of most viewed videos on YouTube from Wikipedia:\n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos/\n",
    "\n",
    "You need to find following details:\n",
    "\n",
    "A) Rank\n",
    "\n",
    "B) Name\n",
    "\n",
    "C) Artist\n",
    "\n",
    "D) Upload date\n",
    "\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=' https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#redirecting\n",
    "redirecting=driver.find_element_by_xpath(\"//a[@class='external text']\")\n",
    "redirecting.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn=driver.find_element_by_xpath(\"//div[@class='mw-search-result-heading']\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "List=[]\n",
    "\n",
    "list= driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter']//tbody//tr//td\")\n",
    "try:\n",
    "    for i in list:\n",
    "        List.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    List.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Name=[]\n",
    "Date=[]\n",
    "Rank=[]\n",
    "Artist=[]\n",
    "Ratings=[]\n",
    "Views=[]\n",
    "\n",
    "for i in List:\n",
    "    for j in range(0,len(List),7):\n",
    "        try:\n",
    "            Rank.append(List[j])\n",
    "        except NoSuchElementException:\n",
    "            Rank.append(\"--\")\n",
    "            \n",
    "    for k in range(1,len(List),7):   \n",
    "        try:\n",
    "            Name.append(List[k])\n",
    "        except NoSuchElementException:\n",
    "            Name.append(\"--\")\n",
    "     \n",
    "    for l in range(2,len(List),7):\n",
    "        try:\n",
    "            Date.append(List[l])\n",
    "        except NoSuchElementException:\n",
    "            Date.append(\"--\")\n",
    "            \n",
    "    for m in range(3,len(List),7):    \n",
    "        try:\n",
    "            Views.append(List[m])\n",
    "        except NoSuchElementException:\n",
    "            Views.append(\"--\")\n",
    "    \n",
    "    for n in range(4,len(List),7):\n",
    "        try:\n",
    "            Artist.append(List[n])\n",
    "        except NoSuchElementException:\n",
    "            Artist.append(\"--\")\n",
    "    \n",
    "    for o in range(5,len(List),7):\n",
    "        try:\n",
    "            Ratings.append(List[o])\n",
    "        except NoSuchElementException:\n",
    "            Ratings.append(\"--\")\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of Rank 15936\n",
      "length of Name 15936\n",
      "length of Date 15936\n",
      "length of Views 15604\n",
      "length of Artist 15604\n",
      "length of Ratings 15604\n"
     ]
    }
   ],
   "source": [
    "print(\"length of Rank\",len(Rank))\n",
    "print(\"length of Name\",len(Name))\n",
    "print(\"length of Date\",len(Date))\n",
    "print(\"length of Views\",len(Views))\n",
    "print(\"length of Artist\",len(Artist))\n",
    "print(\"length of Ratings\",len(Ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[22]</td>\n",
       "      <td>Pinkfong Kids' Songs &amp; Stories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Despacito\"[24]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>7.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>5.60</td>\n",
       "      <td>October 8, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.40</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>[E]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>[F]</td>\n",
       "      <td>6.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15931</th>\n",
       "      <td>youtubedude</td>\n",
       "      <td>2,300,000</td>\n",
       "      <td>December 18, 2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15932</th>\n",
       "      <td>\"Ronaldinho: Touch of Gold\"‡*[148]</td>\n",
       "      <td>Nikesoccer</td>\n",
       "      <td>255,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15933</th>\n",
       "      <td>[X]</td>\n",
       "      <td>\"I/O Brush\"‡*[151]</td>\n",
       "      <td>larfus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15934</th>\n",
       "      <td>[152]</td>\n",
       "      <td></td>\n",
       "      <td>\"Me at the zoo\"[57]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15935</th>\n",
       "      <td>1</td>\n",
       "      <td>[153]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15936 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     rank                    Name  \\\n",
       "0                                      1.  \"Baby Shark Dance\"[22]   \n",
       "1                         \"Despacito\"[24]              Luis Fonsi   \n",
       "2                             LooLoo Kids                    5.60   \n",
       "3                                    5.40        January 30, 2017   \n",
       "4                           April 6, 2015                     [F]   \n",
       "...                                   ...                     ...   \n",
       "15931                         youtubedude               2,300,000   \n",
       "15932  \"Ronaldinho: Touch of Gold\"‡*[148]              Nikesoccer   \n",
       "15933                                 [X]      \"I/O Brush\"‡*[151]   \n",
       "15934                               [152]                           \n",
       "15935                                   1                   [153]   \n",
       "\n",
       "                                Date   \n",
       "0      Pinkfong Kids' Songs & Stories  \n",
       "1                                7.47  \n",
       "2                     October 8, 2016  \n",
       "3                                 [E]  \n",
       "4                                  6.  \n",
       "...                               ...  \n",
       "15931               December 18, 2005  \n",
       "15932                         255,000  \n",
       "15933                          larfus  \n",
       "15934             \"Me at the zoo\"[57]  \n",
       "15935                                  \n",
       "\n",
       "[15936 rows x 3 columns]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the dataframe from the scraped data \n",
    "df=pd.DataFrame({\"rank\":Rank,\"Name\":Name,\"Date \":Date})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Views</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.06</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>[B]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>[C]</td>\n",
       "      <td>3.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[D]</td>\n",
       "      <td>4.</td>\n",
       "      <td>\"Shape of You\"[26]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"See You Again\"[27]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[30]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>4.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15599</th>\n",
       "      <td>28</td>\n",
       "      <td>[145]</td>\n",
       "      <td>[W]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15600</th>\n",
       "      <td>January 9, 2006</td>\n",
       "      <td>12</td>\n",
       "      <td>[147]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15601</th>\n",
       "      <td>October 21, 2005</td>\n",
       "      <td>October 31, 2005</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15602</th>\n",
       "      <td>247,000</td>\n",
       "      <td>October 5, 2005</td>\n",
       "      <td>October 29, 2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15603</th>\n",
       "      <td>jawed</td>\n",
       "      <td>1</td>\n",
       "      <td>April 23, 2005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15604 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Views               Artist  \\\n",
       "0                                                9.06        June 17, 2016   \n",
       "1                                    January 12, 2017                  [C]   \n",
       "2                                                 [D]                   4.   \n",
       "3                                                  5.  \"See You Again\"[27]   \n",
       "4      \"Masha and the Bear – Recipe for Disaster\"[30]           Get Movies   \n",
       "...                                               ...                  ...   \n",
       "15599                                              28                [145]   \n",
       "15600                                 January 9, 2006                   12   \n",
       "15601                                October 21, 2005     October 31, 2005   \n",
       "15602                                         247,000      October 5, 2005   \n",
       "15603                                           jawed                    1   \n",
       "\n",
       "                  Ratings  \n",
       "0                     [B]  \n",
       "1                      3.  \n",
       "2      \"Shape of You\"[26]  \n",
       "3             Wiz Khalifa  \n",
       "4                    4.45  \n",
       "...                   ...  \n",
       "15599                 [W]  \n",
       "15600               [147]  \n",
       "15601                  70  \n",
       "15602    October 29, 2005  \n",
       "15603      April 23, 2005  \n",
       "\n",
       "[15604 rows x 3 columns]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the dataframe from the scraped data \n",
    "df=pd.DataFrame({\"Views\":Views,'Artist':Artist,\"Ratings\":Ratings})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "2. Scrape the details team India’s international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Match title (I.e. 1st ODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=' https://www.bcci.tv/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn1=driver.find_element_by_xpath(\"/html/body/div[2]/div/div[2]/div[2]/nav/ul/li[1]/div[2]\")\n",
    "search_btn1.click()\n",
    "time.sleep(2)\n",
    "\n",
    "search_btn2=driver.find_element_by_xpath(\"/html/body/div[2]/div/div[2]/div[2]/nav/ul/li[1]/div[2]/div/ul/li[1]/a\")\n",
    "search_btn2.click()\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>series</th>\n",
       "      <th>place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wednesday 4th August</td>\n",
       "      <td>1st Test</td>\n",
       "      <td>Trent Bridge, Nottingham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thursday 12th August</td>\n",
       "      <td>2nd Test</td>\n",
       "      <td>Lord's, London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wednesday 25th August</td>\n",
       "      <td>3rd Test</td>\n",
       "      <td>Headingley, Leeds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thursday 2nd September</td>\n",
       "      <td>4th Test</td>\n",
       "      <td>The Oval, London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Friday 10th September</td>\n",
       "      <td>5th Test</td>\n",
       "      <td>Old Trafford, Manchester</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     date    series                     place\n",
       "0    Wednesday 4th August  1st Test  Trent Bridge, Nottingham\n",
       "1    Thursday 12th August  2nd Test            Lord's, London\n",
       "2   Wednesday 25th August  3rd Test         Headingley, Leeds\n",
       "3  Thursday 2nd September  4th Test          The Oval, London\n",
       "4   Friday 10th September  5th Test  Old Trafford, Manchester"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Date=[]\n",
    "Series=[]\n",
    "Place=[]\n",
    "Time=[]\n",
    "\n",
    "date=driver.find_elements_by_xpath(\"//span[@class='fixture__datetime tablet-only']//strong\")\n",
    "for i in date:\n",
    "    try:\n",
    "        Date.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Date.append(\"--\")\n",
    " \n",
    "\n",
    "series=driver.find_elements_by_xpath(\"//strong[@class='fixture__name fixture__name--with-margin']\")\n",
    "for i in series:   \n",
    "    try:\n",
    "        Series.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Series.append(\"--\")\n",
    "\n",
    "place=driver.find_elements_by_xpath(\"//p[@class='fixture__additional-info']//span\")\n",
    "for i in place:\n",
    "    try:\n",
    "        Place.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Place.append(\"--\")\n",
    "        \n",
    " # creating the dataframe from the scraped data \n",
    "df=pd.DataFrame({\"date\":Date,\"series\":Series,\"place\":Place})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Scrape the details of selenium exception from guru99.com.\n",
    "Url = https://www.guru99.com/\n",
    "You need to find following details:\n",
    "A) Name\n",
    "B) Description\n",
    "Note: - From guru99 home page you have to reach to selenium exception handling page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.guru99.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_field_designation=driver.find_element_by_xpath(\"/html/body/div[2]/section[3]/div/div/div/div/div/div/div/div[2]/div/div[1]/div/div/div/form/table/tbody/tr/td[1]/div/table/tbody/tr/td[1]/input\")   #job search bar\n",
    "search_field_designation.clear()    \n",
    "search_field_designation.send_keys(\"selenium exception\")\n",
    "\n",
    "\n",
    "button=driver.find_element_by_xpath(\"/html/body/div[2]/section[3]/div/div/div/div/div/div/div/div[2]/div/div[1]/div/div/div/form/table/tbody/tr/td[2]/button\")\n",
    "button.click()\n",
    "time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.guru99.com/exception-handling-selenium.html',\n",
       " 'https://www.guru99.com/exception-handling-selenium.html',\n",
       " 'https://www.guru99.com/implicit-explicit-waits-selenium.html',\n",
       " 'https://www.guru99.com/implicit-explicit-waits-selenium.html',\n",
       " 'https://www.guru99.com/alert-popup-handling-selenium.html',\n",
       " 'https://www.guru99.com/alert-popup-handling-selenium.html',\n",
       " 'https://www.guru99.com/top-100-selenium-interview-questions-answers.html',\n",
       " 'https://www.guru99.com/top-100-selenium-interview-questions-answers.html',\n",
       " 'https://www.guru99.com/take-screenshot-selenium-webdriver.html',\n",
       " 'https://www.guru99.com/take-screenshot-selenium-webdriver.html',\n",
       " 'https://www.guru99.com/find-element-selenium.html',\n",
       " 'https://www.guru99.com/find-element-selenium.html',\n",
       " 'https://www.guru99.com/listeners-selenium-webdriver.html',\n",
       " 'https://www.guru99.com/listeners-selenium-webdriver.html',\n",
       " 'https://www.guru99.com/database-testing-using-selenium-step-by-step-guide.html',\n",
       " 'https://www.guru99.com/database-testing-using-selenium-step-by-step-guide.html',\n",
       " 'https://www.guru99.com/gecko-marionette-driver-selenium.html',\n",
       " 'https://www.guru99.com/gecko-marionette-driver-selenium.html',\n",
       " 'https://www.guru99.com/ssl-certificate-error-handling-selenium.html',\n",
       " 'https://www.guru99.com/ssl-certificate-error-handling-selenium.html',\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guru_urls = []\n",
    "urls = driver.find_elements_by_xpath('//a[@class=\"gs-title\"]')\n",
    "for url in urls:\n",
    "    try:\n",
    "        guru_urls.append(url.get_attribute(\"href\"))\n",
    "    except NoSuchElementException:\n",
    "        guru_urls.append(\"--\")\n",
    "    \n",
    "guru_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "guru_dict={}\n",
    "guru_dict[\"Name\"]=[]\n",
    "guru_dict[\"Description\"]=[]\n",
    "\n",
    "\n",
    "\n",
    "# Scraping data from each url\n",
    "for url in guru_urls:\n",
    "    if type(url) is str:   #checking if url is empty\n",
    "        driver.get(url)                                                                                                             # Loading the webpage by url\n",
    "        time.sleep(2)\n",
    "\n",
    "        try:\n",
    "            name = driver.find_element_by_xpath('//div[@class=\"page-header\"]')      \n",
    "            guru_dict[\"Name\"].append(name.text)\n",
    "        except NoSuchElementException:\n",
    "            guru_dict['Name'].append('-')\n",
    "            \n",
    "        try:\n",
    "            desc = driver.find_element_by_xpath('//div[@class=\"item-page\"]//div//div//p')      \n",
    "            guru_dict[\"Description\"].append(desc.text)\n",
    "        except NoSuchElementException:\n",
    "            guru_dict['Description'].append('-')\n",
    "    else:\n",
    "        guru_dict['Name'].append('-')\n",
    "        guru_dict['Description'].append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 23\n"
     ]
    }
   ],
   "source": [
    "print(len(guru_dict[\"Name\"]), len(guru_dict[\"Description\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Selenium Exception Handling (Common Exceptions...</td>\n",
       "      <td>An exception is an error that happens at the t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Selenium Exception Handling (Common Exceptions...</td>\n",
       "      <td>An exception is an error that happens at the t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Implicit, Explicit and Fluent Wait in Selenium...</td>\n",
       "      <td>The Implicit Wait in Selenium is used to tell ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Implicit, Explicit and Fluent Wait in Selenium...</td>\n",
       "      <td>The Implicit Wait in Selenium is used to tell ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Selenium Alert &amp; Popup Window Handling: How to...</td>\n",
       "      <td>An Alert in Selenium is a small message box wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Selenium Alert &amp; Popup Window Handling: How to...</td>\n",
       "      <td>An Alert in Selenium is a small message box wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Top 100 Selenium Interview Questions and Answe...</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Top 100 Selenium Interview Questions and Answe...</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How to Take Screenshot in Selenium WebDriver</td>\n",
       "      <td>A Screenshot in Selenium Webdriver is used for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How to Take Screenshot in Selenium WebDriver</td>\n",
       "      <td>A Screenshot in Selenium Webdriver is used for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Find Element and FindElements by XPath in Sele...</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Find Element and FindElements by XPath in Sele...</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TestNG Listeners in Selenium: ITestListener &amp; ...</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>TestNG Listeners in Selenium: ITestListener &amp; ...</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Database Testing using Selenium: Step by Step ...</td>\n",
       "      <td>Name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Database Testing using Selenium: Step by Step ...</td>\n",
       "      <td>Name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Gecko (Marionette) Driver Selenium: Download, ...</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Gecko (Marionette) Driver Selenium: Download, ...</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>How to Handle SSL Certificate in Selenium WebD...</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>How to Handle SSL Certificate in Selenium WebD...</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Name  \\\n",
       "0   Selenium Exception Handling (Common Exceptions...   \n",
       "1   Selenium Exception Handling (Common Exceptions...   \n",
       "2   Implicit, Explicit and Fluent Wait in Selenium...   \n",
       "3   Implicit, Explicit and Fluent Wait in Selenium...   \n",
       "4   Selenium Alert & Popup Window Handling: How to...   \n",
       "5   Selenium Alert & Popup Window Handling: How to...   \n",
       "6   Top 100 Selenium Interview Questions and Answe...   \n",
       "7   Top 100 Selenium Interview Questions and Answe...   \n",
       "8        How to Take Screenshot in Selenium WebDriver   \n",
       "9        How to Take Screenshot in Selenium WebDriver   \n",
       "10  Find Element and FindElements by XPath in Sele...   \n",
       "11  Find Element and FindElements by XPath in Sele...   \n",
       "12  TestNG Listeners in Selenium: ITestListener & ...   \n",
       "13  TestNG Listeners in Selenium: ITestListener & ...   \n",
       "14  Database Testing using Selenium: Step by Step ...   \n",
       "15  Database Testing using Selenium: Step by Step ...   \n",
       "16  Gecko (Marionette) Driver Selenium: Download, ...   \n",
       "17  Gecko (Marionette) Driver Selenium: Download, ...   \n",
       "18  How to Handle SSL Certificate in Selenium WebD...   \n",
       "19  How to Handle SSL Certificate in Selenium WebD...   \n",
       "20                                                  -   \n",
       "21                                                  -   \n",
       "22                                                  -   \n",
       "\n",
       "                                          Description  \n",
       "0   An exception is an error that happens at the t...  \n",
       "1   An exception is an error that happens at the t...  \n",
       "2   The Implicit Wait in Selenium is used to tell ...  \n",
       "3   The Implicit Wait in Selenium is used to tell ...  \n",
       "4   An Alert in Selenium is a small message box wh...  \n",
       "5   An Alert in Selenium is a small message box wh...  \n",
       "6                                                   -  \n",
       "7                                                   -  \n",
       "8   A Screenshot in Selenium Webdriver is used for...  \n",
       "9   A Screenshot in Selenium Webdriver is used for...  \n",
       "10                                                  -  \n",
       "11                                                  -  \n",
       "12                                                  -  \n",
       "13                                                  -  \n",
       "14                                               Name  \n",
       "15                                               Name  \n",
       "16                                                  -  \n",
       "17                                                  -  \n",
       "18                                                  -  \n",
       "19                                                  -  \n",
       "20                                                  -  \n",
       "21                                                  -  \n",
       "22                                                  -  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guru_df = pd.DataFrame.from_dict(guru_dict)\n",
    "guru_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details:\n",
    "\n",
    "A) Rank\n",
    "\n",
    "B) State\n",
    "\n",
    "C) GSDP at current price (19-20)\n",
    "\n",
    "D) GSDP at current price (18-19)\n",
    "\n",
    "E) Share(18-19)\n",
    "\n",
    "F) GDP($ billion)\n",
    "\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opning STATISTICSTIMES.com\n",
    "driver.get('http://statisticstimes.com/')\n",
    "time.sleep(3)\n",
    "\n",
    "#finding economy button\n",
    "try:\n",
    "    economy_button = driver.find_element_by_xpath('/html/body/div[2]/div[1]/div[2]/div[2]/button')                      # Button to close login popup\n",
    "    economy_button.click()\n",
    "except NoSuchElementException : \n",
    "    print(\"No economy button\")\n",
    "time.sleep(2)    \n",
    "    \n",
    "#finding the state button\n",
    "search_bar = driver.find_element_by_xpath('/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]')    \n",
    "search_bar.click()               \n",
    "time.sleep(4) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the :GDP of Indian states\n",
    "search_bar2 = driver.find_element_by_xpath('/html/body/div[2]/div[2]/div[2]/ul/li[1]/a')    \n",
    "search_bar2.click()               \n",
    "time.sleep(2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rank=[]\n",
    "Name=[]\n",
    "GSDP1920_1=[]\n",
    "GSDP1819_1= []\n",
    "GSDP1920_2=[]\n",
    "GSDP1819_2= []\n",
    "Share=[]\n",
    "GDP=[]\n",
    "\n",
    "Lists=[]\n",
    "lists=driver.find_elements_by_xpath(\"//table[@id='table_id']//tbody//tr//td\")\n",
    "for i in lists:\n",
    "    try:\n",
    "        Lists.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Lists.append('-')    \n",
    "        \n",
    "\n",
    "#scrapping rank\n",
    "for i in range(0,len(Lists),8):\n",
    "     Rank.append(Lists[i])\n",
    "        \n",
    "#scrapping names of state\n",
    "for i in range(1,len(Lists),8):\n",
    "     Name.append(Lists[i])\n",
    "\n",
    "#scrapping GSDP at current price (19-20)\n",
    "for i in range(2,len(Lists),8):\n",
    "    GSDP1920_1.append(Lists[i])       \n",
    "        \n",
    "#GSDP 201819 at current prices\n",
    "for i in range(3,len(Lists),8):\n",
    "    GSDP1819_1.append(Lists[i])\n",
    "    \n",
    "#Share 2018-19\n",
    "for i in range(4,len(Lists),8):\n",
    "    Share.append(Lists[i])\n",
    "\n",
    "#GDP\n",
    "for i in range(5,len(Lists),8):\n",
    "    GDP.append(Lists[i])\n",
    "\n",
    "    \n",
    "#GSDP 2019-2020 at 2011/12 prices\n",
    "for i in range(6,len(Lists),8):\n",
    "    GSDP1920_2.append(Lists[i])\n",
    "\n",
    "\n",
    "#GSDP 2018-2019 at 2011-12\n",
    "for i in range(7,len(Lists),8):\n",
    "    GSDP1819_2.append(Lists[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "print(len(Rank))\n",
    "print(len(Name))\n",
    "print(len(GSDP1920_1))\n",
    "print(len(GSDP1819_1))\n",
    "print(len(Share))\n",
    "print(len(GDP))\n",
    "print(len(GSDP1920_2))\n",
    "print(len(GSDP1819_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>GSDP of 2019/20 at current prices</th>\n",
       "      <th>GDP of states in billion</th>\n",
       "      <th>Share</th>\n",
       "      <th>GSDP of 2019/20 at 2011/12 prices</th>\n",
       "      <th>GSDP of 2018/19 at 2011/12 prices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>399.921</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>-</td>\n",
       "      <td>2,039,074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>247.629</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>1,312,929</td>\n",
       "      <td>1,215,307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>240.726</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>1,166,817</td>\n",
       "      <td>1,123,982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>228.290</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>-</td>\n",
       "      <td>1,186,379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>226.806</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>1,156,039</td>\n",
       "      <td>1,091,077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>165.556</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>793,223</td>\n",
       "      <td>739,525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>942,586</td>\n",
       "      <td>143.179</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>711,627</td>\n",
       "      <td>677,428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>862,957</td>\n",
       "      <td>131.083</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>672,018</td>\n",
       "      <td>621,301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>861,031</td>\n",
       "      <td>130.791</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>663,258</td>\n",
       "      <td>612,828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>809,592</td>\n",
       "      <td>122.977</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>561,801</td>\n",
       "      <td>522,009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>781,653</td>\n",
       "      <td>118.733</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>-</td>\n",
       "      <td>559,412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>774,870</td>\n",
       "      <td>117.703</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>634,408</td>\n",
       "      <td>590,569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>734,163</td>\n",
       "      <td>111.519</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>572,240</td>\n",
       "      <td>531,085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>530,363</td>\n",
       "      <td>80.562</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>414,977</td>\n",
       "      <td>375,651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>526,376</td>\n",
       "      <td>79.957</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>418,868</td>\n",
       "      <td>397,669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>487,805</td>\n",
       "      <td>74.098</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>396,499</td>\n",
       "      <td>376,877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>315,881</td>\n",
       "      <td>47.982</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>-</td>\n",
       "      <td>234,048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>304,063</td>\n",
       "      <td>46.187</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>243,477</td>\n",
       "      <td>231,182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>297,204</td>\n",
       "      <td>45.145</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>240,036</td>\n",
       "      <td>224,986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>245,895</td>\n",
       "      <td>37.351</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>-</td>\n",
       "      <td>193,273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>155,956</td>\n",
       "      <td>23.690</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>-</td>\n",
       "      <td>112,755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>153,845</td>\n",
       "      <td>23.369</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>124,403</td>\n",
       "      <td>117,851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>73,170</td>\n",
       "      <td>11.115</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>63,408</td>\n",
       "      <td>57,787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>49,845</td>\n",
       "      <td>7.571</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>40,583</td>\n",
       "      <td>36,963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>42,114</td>\n",
       "      <td>6.397</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>-</td>\n",
       "      <td>31,192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>34,433</td>\n",
       "      <td>5.230</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>25,093</td>\n",
       "      <td>23,013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>33,481</td>\n",
       "      <td>5.086</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>26,695</td>\n",
       "      <td>24,682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>28,723</td>\n",
       "      <td>4.363</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>20,017</td>\n",
       "      <td>18,722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>27,870</td>\n",
       "      <td>4.233</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>20,673</td>\n",
       "      <td>19,300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>27,283</td>\n",
       "      <td>4.144</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>-</td>\n",
       "      <td>17,647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>24,603</td>\n",
       "      <td>3.737</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>-</td>\n",
       "      <td>16,676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>22,287</td>\n",
       "      <td>3.385</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>18,797</td>\n",
       "      <td>16,478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                       Name GSDP of 2019/20 at current prices  \\\n",
       "0     1                Maharashtra                         2,632,792   \n",
       "1     2                 Tamil Nadu                         1,630,208   \n",
       "2     3              Uttar Pradesh                         1,584,764   \n",
       "3     4                    Gujarat                         1,502,899   \n",
       "4     5                  Karnataka                         1,493,127   \n",
       "5     6                West Bengal                         1,089,898   \n",
       "6     7                  Rajasthan                           942,586   \n",
       "7     8             Andhra Pradesh                           862,957   \n",
       "8     9                  Telangana                           861,031   \n",
       "9    10             Madhya Pradesh                           809,592   \n",
       "10   11                     Kerala                           781,653   \n",
       "11   12                      Delhi                           774,870   \n",
       "12   13                    Haryana                           734,163   \n",
       "13   14                      Bihar                           530,363   \n",
       "14   15                     Punjab                           526,376   \n",
       "15   16                     Odisha                           487,805   \n",
       "16   17                      Assam                           315,881   \n",
       "17   18               Chhattisgarh                           304,063   \n",
       "18   19                  Jharkhand                           297,204   \n",
       "19   20                Uttarakhand                           245,895   \n",
       "20   21            Jammu & Kashmir                           155,956   \n",
       "21   22           Himachal Pradesh                           153,845   \n",
       "22   23                        Goa                            73,170   \n",
       "23   24                    Tripura                            49,845   \n",
       "24   25                 Chandigarh                            42,114   \n",
       "25   26                 Puducherry                            34,433   \n",
       "26   27                  Meghalaya                            33,481   \n",
       "27   28                     Sikkim                            28,723   \n",
       "28   29                    Manipur                            27,870   \n",
       "29   30                   Nagaland                            27,283   \n",
       "30   31          Arunachal Pradesh                            24,603   \n",
       "31   32                    Mizoram                            22,287   \n",
       "32   33  Andaman & Nicobar Islands                                 -   \n",
       "\n",
       "   GDP of states in billion   Share GSDP of 2019/20 at 2011/12 prices  \\\n",
       "0                   399.921  13.94%                                 -   \n",
       "1                   247.629   8.63%                         1,312,929   \n",
       "2                   240.726   8.39%                         1,166,817   \n",
       "3                   228.290   7.96%                                 -   \n",
       "4                   226.806   7.91%                         1,156,039   \n",
       "5                   165.556   5.77%                           793,223   \n",
       "6                   143.179   4.99%                           711,627   \n",
       "7                   131.083   4.57%                           672,018   \n",
       "8                   130.791   4.56%                           663,258   \n",
       "9                   122.977   4.29%                           561,801   \n",
       "10                  118.733   4.14%                                 -   \n",
       "11                  117.703   4.10%                           634,408   \n",
       "12                  111.519   3.89%                           572,240   \n",
       "13                   80.562   2.81%                           414,977   \n",
       "14                   79.957   2.79%                           418,868   \n",
       "15                   74.098   2.58%                           396,499   \n",
       "16                   47.982   1.67%                                 -   \n",
       "17                   46.187   1.61%                           243,477   \n",
       "18                   45.145   1.57%                           240,036   \n",
       "19                   37.351   1.30%                                 -   \n",
       "20                   23.690   0.83%                                 -   \n",
       "21                   23.369   0.81%                           124,403   \n",
       "22                   11.115   0.39%                            63,408   \n",
       "23                    7.571   0.26%                            40,583   \n",
       "24                    6.397   0.22%                                 -   \n",
       "25                    5.230   0.18%                            25,093   \n",
       "26                    5.086   0.18%                            26,695   \n",
       "27                    4.363   0.15%                            20,017   \n",
       "28                    4.233   0.15%                            20,673   \n",
       "29                    4.144   0.14%                                 -   \n",
       "30                    3.737   0.13%                                 -   \n",
       "31                    3.385   0.12%                            18,797   \n",
       "32                        -       -                                 -   \n",
       "\n",
       "   GSDP of 2018/19 at 2011/12 prices  \n",
       "0                          2,039,074  \n",
       "1                          1,215,307  \n",
       "2                          1,123,982  \n",
       "3                          1,186,379  \n",
       "4                          1,091,077  \n",
       "5                            739,525  \n",
       "6                            677,428  \n",
       "7                            621,301  \n",
       "8                            612,828  \n",
       "9                            522,009  \n",
       "10                           559,412  \n",
       "11                           590,569  \n",
       "12                           531,085  \n",
       "13                           375,651  \n",
       "14                           397,669  \n",
       "15                           376,877  \n",
       "16                           234,048  \n",
       "17                           231,182  \n",
       "18                           224,986  \n",
       "19                           193,273  \n",
       "20                           112,755  \n",
       "21                           117,851  \n",
       "22                            57,787  \n",
       "23                            36,963  \n",
       "24                            31,192  \n",
       "25                            23,013  \n",
       "26                            24,682  \n",
       "27                            18,722  \n",
       "28                            19,300  \n",
       "29                            17,647  \n",
       "30                            16,676  \n",
       "31                            16,478  \n",
       "32                                 -  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Rank':Rank,'Name':Name,'GSDP of 2019/20 at current prices':GSDP1920_1,'GSDP of 2019/20 at current prices':GSDP1819_1,\"GDP of states in billion\":GDP,\"Share\":Share,\"GSDP of 2019/20 at 2011/12 prices\":GSDP1920_2,'GSDP of 2018/19 at 2011/12 prices':GSDP1819_2})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape the details of trending repositories on Github.com.\n",
    "\n",
    "Url = https://github.com/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Repository title\n",
    "\n",
    "B) Repository description\n",
    "\n",
    "C) Contributors count\n",
    "\n",
    "D) Language used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: - From the home page you have to click on the trending option from Explore menu through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No explore button\n"
     ]
    }
   ],
   "source": [
    "# opning github.com\n",
    "driver.get('https://github.com/')\n",
    "time.sleep(3)\n",
    "\n",
    "#finding explore button\n",
    "try:\n",
    "    economy_button = driver.find_element_by_xpath('/html/body/div[1]/header/div[3]/nav/a[4]')                      # Button to close login popup\n",
    "    economy_button.click()\n",
    "except NoSuchElementException : \n",
    "    print(\"No explore button\")\n",
    "time.sleep(2)    \n",
    "\n",
    "#finding the state button\n",
    "sign_in = driver.find_element_by_xpath('/html/body/div[1]/header/div/div[2]/div[2]/div[2]/a')    \n",
    "sign_in.click()               \n",
    "time.sleep(4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "username=driver.find_element_by_id('login_field')\n",
    "username.send_keys(\"aneeshabsoman1994\")  #entering Video name\n",
    "time.sleep(1)\n",
    "\n",
    "password=driver.find_element_by_id('password')\n",
    "password.send_keys(\"fliprobo1994\")  #entering Video name\n",
    "time.sleep(1)\n",
    "\n",
    "sign_in_button = driver.find_element_by_xpath('//*[@id=\"login\"]/div[4]/form/div/input[12]')\n",
    "sign_in_button.click()               \n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding explore button\n",
    "try:\n",
    "    economy_button = driver.find_element_by_xpath('/html/body/div[1]/header/div[3]/nav/a[4]')                      # Button to close login popup\n",
    "    economy_button.click()\n",
    "except NoSuchElementException : \n",
    "    print(\"No explore button\")\n",
    "time.sleep(2)    \n",
    "\n",
    "#finding trending button\n",
    "try:\n",
    "    trending_button = driver.find_element_by_xpath('/html/body/div[4]/main/div[1]/nav/div/a[3]')                      # Button to close login popup\n",
    "    trending_button.click()\n",
    "except NoSuchElementException : \n",
    "    print(\"No trending button\")\n",
    "time.sleep(2) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping title\n",
    "Title=[]\n",
    "Description=[]\n",
    "Language=[]\n",
    "List=[]\n",
    "Contributor=[]\n",
    "\n",
    "#scrapping title \n",
    "try:\n",
    "    title=driver.find_elements_by_xpath(\"//span[@class='text-normal']\")\n",
    "    for i in title:\n",
    "          Title.append(i.text)\n",
    "except NoSuchElementException:\n",
    "          Title.append(\"-\")\n",
    "  \n",
    "#scrapping languages\n",
    "Lists1=[]\n",
    "lists1=driver.find_elements_by_xpath(\"//span[@class='d-inline-block ml-0 mr-3']//span\")\n",
    "for i in lists1:\n",
    "    try:\n",
    "        Lists1.append(i.text.split())\n",
    "    except NoSuchElementException:\n",
    "        Lists1.append('-')        \n",
    "\n",
    "for i in range(1,len(Lists1),2):\n",
    "        Language.append(Lists1[i])\n",
    "\n",
    "\n",
    " #scrapping description\n",
    "try:\n",
    "    desc=driver.find_elements_by_xpath(\"//article[@class='Box-row']//p\")\n",
    "    for i in desc:\n",
    "          Description.append(i.text)\n",
    "except NoSuchElementException:\n",
    "          Description.append(\"--\")\n",
    "\n",
    "\n",
    "\n",
    "#scrapping Number of contributors\n",
    "try:\n",
    "    link=driver.find_elements_by_xpath(\"//a[@class='Link--muted d-inline-block mr-3']\")\n",
    "    for i in link:\n",
    "          List.append(i.text)\n",
    "except NoSuchElementException:\n",
    "          List.append(\"--\")\n",
    "        \n",
    "for i in range(0,len(List),2):\n",
    "    try:\n",
    "        Contributor.append(List[i])\n",
    "    except NoSuchElementException:\n",
    "        Contributor.append(\"--\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "titles length 25\n",
      "Description length 23\n",
      "Language 21\n",
      "Contributor 25\n"
     ]
    }
   ],
   "source": [
    "print(\"titles length\",len(Title))\n",
    "print(\"Description length\",len(Description))\n",
    "print(\"Language\",len(Language))\n",
    "print(\"Number of Contributors\",len(Contributor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Linux Kernel Module Programming Guide (updated for 5.x kernels)',\n",
       " 'openpilot is an open source driver assistance system. openpilot performs the functions of Automated Lane Centering and Adaptive Cruise Control for over 100 supported car makes and models.',\n",
       " '12 weeks, 25 lessons, 50 quizzes, classic Machine Learning for all',\n",
       " 'Learn how to design large-scale systems. Prep for the system design interview. Includes Anki flashcards.',\n",
       " '24 Lessons, 12 Weeks, Get Started as a Web Developer',\n",
       " 'The open-source repo for docs.github.com',\n",
       " 'A collection of modern/faster/saner alternatives to common unix commands.',\n",
       " '🐶 Automated code review tool integrated with any code analysis tools regardless of programming language',\n",
       " '信息收集自动化工具',\n",
       " 'Ergonomic and modular web framework built with Tokio, Tower, and Hyper',\n",
       " '🚀🚀🚀vue3,vue3.0,vue,vue3.x,vue.js,vue后台管理,admin,vue-admin,vue-element-admin,ant-design，vue-admin-beautiful-pro,vab admin pro,vab admin plus主线版本基于element-plus、element-ui、ant-design-vue三者并行开发维护，同时支持电脑，手机，平板，切换分支查看不同的vue版本，element-plus版本已发布(vue3,vue3.0,vue,vue3.x,vue.js)程序无国界，但程序员有国界，中国国家尊严不容挑衅，如果您在特殊时期继续购买HM、耐克、阿迪达斯等品牌那么您将无权继续使用Vab',\n",
       " 'A list of awesome beginners-friendly projects.',\n",
       " 'Prometheus Alertmanager',\n",
       " 'Free, open source crypto trading bot',\n",
       " 'Gin is a HTTP web framework written in Go (Golang). It features a Martini-like API with much better performance -- up to 40 times faster. If you need smashing performance, get yourself some Gin.',\n",
       " '📗 SheetJS Community Edition -- Spreadsheet Data Toolkit',\n",
       " 'Prowler is a security tool to perform AWS security best practices assessments, audits, incident response, continuous monitoring, hardening and forensics readiness. It contains all CIS controls listed here https://d0.awsstatic.com/whitepapers/compliance/AWS_CIS_Foundations_Benchmark.pdf and more than 100 additional checks that help on GDPR, HIPAA…',\n",
       " 'GitHub Actions virtual environments',\n",
       " 'Generic Signature Format for SIEM Systems',\n",
       " 'OpenMMLab Computer Vision Foundation',\n",
       " 'This repository is for active development of the Azure SDK for .NET. For consumers of the SDK we recommend visiting our public developer docs at https://docs.microsoft.com/en-us/dotnet/azure/ or our versioned developer docs at https://azure.github.io/azure-sdk-for-net.',\n",
       " 'A curated list of awesome frameworks, libraries and software for the Java programming language.',\n",
       " 'Trying to tame the three-headed dog.']"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Number of Contributors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sysprog21 /</td>\n",
       "      <td>1,353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>commaai /</td>\n",
       "      <td>26,736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>microsoft /</td>\n",
       "      <td>15,450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>donnemartin /</td>\n",
       "      <td>140,487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>microsoft /</td>\n",
       "      <td>31,720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>github /</td>\n",
       "      <td>5,714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ibraheemdev /</td>\n",
       "      <td>13,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>reviewdog /</td>\n",
       "      <td>3,866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0x727 /</td>\n",
       "      <td>577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tokio-rs /</td>\n",
       "      <td>1,096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>krishnaik06 /</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>chuzhixin /</td>\n",
       "      <td>9,749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MunGell /</td>\n",
       "      <td>33,607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>prometheus /</td>\n",
       "      <td>4,278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>freqtrade /</td>\n",
       "      <td>10,219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gin-gonic /</td>\n",
       "      <td>50,203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SheetJS /</td>\n",
       "      <td>26,587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>toniblyx /</td>\n",
       "      <td>3,711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>actions /</td>\n",
       "      <td>3,701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SigmaHQ /</td>\n",
       "      <td>3,863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>open-mmlab /</td>\n",
       "      <td>2,820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Azure /</td>\n",
       "      <td>2,583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Hiroshiba /</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>akullpp /</td>\n",
       "      <td>29,563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>GhostPack /</td>\n",
       "      <td>1,630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Title Number of Contributors\n",
       "0     sysprog21 /                  1,353\n",
       "1       commaai /                 26,736\n",
       "2     microsoft /                 15,450\n",
       "3   donnemartin /                140,487\n",
       "4     microsoft /                 31,720\n",
       "5        github /                  5,714\n",
       "6   ibraheemdev /                 13,990\n",
       "7     reviewdog /                  3,866\n",
       "8         0x727 /                    577\n",
       "9      tokio-rs /                  1,096\n",
       "10  krishnaik06 /                    160\n",
       "11    chuzhixin /                  9,749\n",
       "12      MunGell /                 33,607\n",
       "13   prometheus /                  4,278\n",
       "14    freqtrade /                 10,219\n",
       "15    gin-gonic /                 50,203\n",
       "16      SheetJS /                 26,587\n",
       "17     toniblyx /                  3,711\n",
       "18      actions /                  3,701\n",
       "19      SigmaHQ /                  3,863\n",
       "20   open-mmlab /                  2,820\n",
       "21        Azure /                  2,583\n",
       "22    Hiroshiba /                    400\n",
       "23      akullpp /                 29,563\n",
       "24    GhostPack /                  1,630"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Title':Title,'Number of Contributors':Contributor})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape the details of top 100 songs on billboard.com.\n",
    "\n",
    "Url = https://www.billboard.com/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Song name\n",
    "\n",
    "B) Artist name\n",
    "\n",
    "C) Last week rank\n",
    "\n",
    "D) Peak rank\n",
    "\n",
    "E) Weeks on board\n",
    "\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opning bill board.com\n",
    "driver.get('https://www.billboard.com/')\n",
    "time.sleep(3)\n",
    "\n",
    "#finding charts button\n",
    "try:\n",
    "    charts_button = driver.find_element_by_xpath('/html/body/div[2]/div[2]/div[2]/header/div/ul/li[1]/a')                      # Button to close login popup\n",
    "    charts_button.click()\n",
    "except NoSuchElementException : \n",
    "    print(\"No charts button\")\n",
    "time.sleep(2)  \n",
    "\n",
    "#finding hot100 button\n",
    "try:\n",
    "    hot100_button = driver.find_element_by_xpath('/html/body/main/div[2]/div/div[1]/a/div[2]/div[1]')                      # Button to close login popup\n",
    "    hot100_button.click()\n",
    "except NoSuchElementException : \n",
    "    print(\"No hot100 button\")\n",
    "time.sleep(2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping title\n",
    "Title=[]\n",
    "Artist=[]\n",
    "Lastweekrank=[]\n",
    "PeakRange=[]\n",
    "WeeksOnChart=[]\n",
    "\n",
    "\n",
    "#scrapping title \n",
    "try:\n",
    "    title1=driver.find_elements_by_xpath(\"//span[@class='chart-element__information__song text--truncate color--primary']\")\n",
    "    for i in title1:\n",
    "          Title.append(i.text)\n",
    "except NoSuchElementException:\n",
    "          Title.append(\"-\")\n",
    "        \n",
    " #scrapping artist\n",
    "try:\n",
    "    artist=driver.find_elements_by_xpath(\"//span[@class='chart-element__information__artist text--truncate color--secondary']\")\n",
    "    for i in artist:\n",
    "          Artist.append(i.text)\n",
    "except NoSuchElementException:\n",
    "          Artist.append(\"--\")\n",
    "\n",
    "#scrapping lastweekrank\n",
    "try:\n",
    "    lastweekrank=driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--last']\")\n",
    "    for i in lastweekrank:\n",
    "          Lastweekrank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "          Lastweekrank.append(\"--\")\n",
    "        \n",
    "\n",
    "#Scrapping WeeksOnChart\n",
    "peakRange=driver.find_elements_by_xpath(\"//div[@class='chart-element__metas chart-element__metas--large display--flex flex--y-center']\")\n",
    "for i in peakRange:\n",
    "    try:\n",
    "        PeakRange.append(i.text.split()[1])\n",
    "    except NoSuchElementException:\n",
    "        PeakRange.append('-') \n",
    "        \n",
    "#Scrapping WeeksOnChart\n",
    "weeksOnChart=driver.find_elements_by_xpath(\"//div[@class='chart-element__metas chart-element__metas--large display--flex flex--y-center']\")\n",
    "for i in weeksOnChart:\n",
    "    try:\n",
    "        WeeksOnChart.append(i.text.split()[2])\n",
    "    except NoSuchElementException:\n",
    "        WeeksOnChart.append('-') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of Title 100\n",
      "length of Artist 100\n",
      "length of Lastweekrank 100\n",
      "length of PeakRange 100\n",
      "length of WeeksOnChart 100\n"
     ]
    }
   ],
   "source": [
    "print(\"length of Title\",len(Title))\n",
    "print(\"length of Artist\",len(Artist))\n",
    "print(\"length of Lastweekrank\",len(Lastweekrank))\n",
    "print(\"length of PeakRange\",len(PeakRange))\n",
    "print(\"length of WeeksOnChart\",len(WeeksOnChart))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Lastweekrank</th>\n",
       "      <th>PeakRange</th>\n",
       "      <th>WeeksOnChart</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Butter</td>\n",
       "      <td>BTS</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Industry Baby</td>\n",
       "      <td>Lil Nas X &amp; Jack Harlow</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good 4 U</td>\n",
       "      <td>Olivia Rodrigo</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stay</td>\n",
       "      <td>The Kid LAROI &amp; Justin Bieber</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Levitating</td>\n",
       "      <td>Dua Lipa Featuring DaBaby</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Minimum Wage</td>\n",
       "      <td>Blake Shelton</td>\n",
       "      <td>83</td>\n",
       "      <td>67</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Working</td>\n",
       "      <td>Tate McRae X Khalid</td>\n",
       "      <td>-</td>\n",
       "      <td>88</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Holy Smokes</td>\n",
       "      <td>Trippie Redd Featuring Lil Uzi Vert</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>WUSYANAME</td>\n",
       "      <td>Tyler, The Creator Featuring YoungBoy Never Br...</td>\n",
       "      <td>91</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Still Chose You</td>\n",
       "      <td>The Kid LAROI Featuring Mustard</td>\n",
       "      <td>-</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Title                                             Artist  \\\n",
       "0            Butter                                                BTS   \n",
       "1     Industry Baby                            Lil Nas X & Jack Harlow   \n",
       "2          Good 4 U                                     Olivia Rodrigo   \n",
       "3              Stay                      The Kid LAROI & Justin Bieber   \n",
       "4        Levitating                          Dua Lipa Featuring DaBaby   \n",
       "..              ...                                                ...   \n",
       "95     Minimum Wage                                      Blake Shelton   \n",
       "96          Working                                Tate McRae X Khalid   \n",
       "97      Holy Smokes                Trippie Redd Featuring Lil Uzi Vert   \n",
       "98        WUSYANAME  Tyler, The Creator Featuring YoungBoy Never Br...   \n",
       "99  Still Chose You                    The Kid LAROI Featuring Mustard   \n",
       "\n",
       "   Lastweekrank PeakRange WeeksOnChart  \n",
       "0             1         1           10  \n",
       "1             -         2            1  \n",
       "2             2         1           11  \n",
       "3             4         3            3  \n",
       "4             3         2           43  \n",
       "..          ...       ...          ...  \n",
       "95           83        67           12  \n",
       "96            -        88            5  \n",
       "97           50        50            2  \n",
       "98           91        14            5  \n",
       "99            -       100            1  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Title':Title,'Artist':Artist,'Lastweekrank':Lastweekrank,\"PeakRange\":PeakRange,\"WeeksOnChart\":WeeksOnChart})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# question 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape the details of Data science recruiters from naukri.com.\n",
    "\n",
    "Url = https://www.naukri.com/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Name\n",
    "\n",
    "B) Designation\n",
    "\n",
    "C) Company\n",
    "\n",
    "D) Skills they hire for\n",
    "\n",
    "E) Location\n",
    "\n",
    "Note: - From naukri.com homepage click on the recruiters option and the on the search pane type Data science and\n",
    "click on search. All this should be done through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opning naukari.com\n",
    "driver.get('https://www.naukri.com/')\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering “Data science” in “Skill,Designations,Companies” field \n",
    "search_field_designation=driver.find_element_by_id(\"qsb-keyword-sugg\") #job search bar\n",
    "search_field_designation.send_keys(\"Data Analyst\")\n",
    "\n",
    "# clicking the search button\n",
    "search_button=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_button.click()\n",
    "time.sleep(4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape all product urls\n",
    "urls = []\n",
    "start=0\n",
    "end=2\n",
    "for page in range(start,end):#for loop for scrapping 3 page\n",
    "    url=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')       \n",
    "    for i in url:\n",
    "        urls.append(i.get_attribute(\"href\"))                        \n",
    "    nxt_button=driver.find_element_by_xpath(\"//a[@class='fright fs14 btn-secondary br2']\")     \n",
    "    nxt_button.click()\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Name=[]\n",
    "Description=[]\n",
    "Designation=[]\n",
    "Location=[]\n",
    "\n",
    "for url in urls:\n",
    "    driver.get(url)                                                                                                                   \n",
    "    time.sleep(2)\n",
    "    \n",
    "    try:\n",
    "        name = driver.find_element_by_xpath('//h1[@class=\"jd-header-title\"]')      \n",
    "        Name.append(name.text)\n",
    "    except NoSuchElementException:\n",
    "        Name.append('-')\n",
    "     \n",
    "    try:\n",
    "        desc = driver.find_element_by_xpath('//div[@class=\"dang-inner-html\"]')      \n",
    "        Description.append(desc.text)\n",
    "    except NoSuchElementException:\n",
    "        Description.append('-')\n",
    "        \n",
    "        \n",
    "    \n",
    "    try:\n",
    "        name = driver.find_element_by_xpath('//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]')      \n",
    "        Name.append(name.text)\n",
    "    except NoSuchElementException:\n",
    "        Name.append('-')\n",
    "     \n",
    "   \n",
    "    \n",
    "    \n",
    "df=pd.DataFrame({'Name':Name,'Description':Description,'Location':Location})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# question 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape the details of Highest selling novels.\n",
    "\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-greycompare/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Book name\n",
    "\n",
    "B) Author name\n",
    "\n",
    "C) Volumes sold\n",
    "\n",
    "D) Publisher\n",
    "\n",
    "E) Genre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opning guardian.com\n",
    "driver.get('https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare')\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " 'Da Vinci Code,The',\n",
       " 'Brown, Dan',\n",
       " '5,094,805',\n",
       " 'Transworld',\n",
       " 'Crime, Thriller & Adventure',\n",
       " '2',\n",
       " 'Harry Potter and the Deathly Hallows',\n",
       " 'Rowling, J.K.',\n",
       " '4,475,152',\n",
       " 'Bloomsbury',\n",
       " \"Children's Fiction\",\n",
       " '3',\n",
       " \"Harry Potter and the Philosopher's Stone\",\n",
       " 'Rowling, J.K.',\n",
       " '4,200,654',\n",
       " 'Bloomsbury',\n",
       " \"Children's Fiction\",\n",
       " '4',\n",
       " 'Harry Potter and the Order of the Phoenix',\n",
       " 'Rowling, J.K.',\n",
       " '4,179,479',\n",
       " 'Bloomsbury',\n",
       " \"Children's Fiction\",\n",
       " '5',\n",
       " 'Fifty Shades of Grey',\n",
       " 'James, E. L.',\n",
       " '3,758,936',\n",
       " 'Random House',\n",
       " 'Romance & Sagas',\n",
       " '6',\n",
       " 'Harry Potter and the Goblet of Fire',\n",
       " 'Rowling, J.K.',\n",
       " '3,583,215',\n",
       " 'Bloomsbury',\n",
       " \"Children's Fiction\",\n",
       " '7',\n",
       " 'Harry Potter and the Chamber of Secrets',\n",
       " 'Rowling, J.K.',\n",
       " '3,484,047',\n",
       " 'Bloomsbury',\n",
       " \"Children's Fiction\",\n",
       " '8',\n",
       " 'Harry Potter and the Prisoner of Azkaban',\n",
       " 'Rowling, J.K.',\n",
       " '3,377,906',\n",
       " 'Bloomsbury',\n",
       " \"Children's Fiction\",\n",
       " '9',\n",
       " 'Angels and Demons',\n",
       " 'Brown, Dan',\n",
       " '3,193,946',\n",
       " 'Transworld',\n",
       " 'Crime, Thriller & Adventure',\n",
       " '10',\n",
       " \"Harry Potter and the Half-blood Prince:Children's Edition\",\n",
       " 'Rowling, J.K.',\n",
       " '2,950,264',\n",
       " 'Bloomsbury',\n",
       " \"Children's Fiction\",\n",
       " '11',\n",
       " 'Fifty Shades Darker',\n",
       " 'James, E. L.',\n",
       " '2,479,784',\n",
       " 'Random House',\n",
       " 'Romance & Sagas',\n",
       " '12',\n",
       " 'Twilight',\n",
       " 'Meyer, Stephenie',\n",
       " '2,315,405',\n",
       " 'Little, Brown Book',\n",
       " 'Young Adult Fiction',\n",
       " '13',\n",
       " 'Girl with the Dragon Tattoo,The:Millennium Trilogy',\n",
       " 'Larsson, Stieg',\n",
       " '2,233,570',\n",
       " 'Quercus',\n",
       " 'Crime, Thriller & Adventure',\n",
       " '14',\n",
       " 'Fifty Shades Freed',\n",
       " 'James, E. L.',\n",
       " '2,193,928',\n",
       " 'Random House',\n",
       " 'Romance & Sagas',\n",
       " '15',\n",
       " 'Lost Symbol,The',\n",
       " 'Brown, Dan',\n",
       " '2,183,031',\n",
       " 'Transworld',\n",
       " 'Crime, Thriller & Adventure',\n",
       " '16',\n",
       " 'New Moon',\n",
       " 'Meyer, Stephenie',\n",
       " '2,152,737',\n",
       " 'Little, Brown Book',\n",
       " 'Young Adult Fiction',\n",
       " '17',\n",
       " 'Deception Point',\n",
       " 'Brown, Dan',\n",
       " '2,062,145',\n",
       " 'Transworld',\n",
       " 'Crime, Thriller & Adventure',\n",
       " '18',\n",
       " 'Eclipse',\n",
       " 'Meyer, Stephenie',\n",
       " '2,052,876',\n",
       " 'Little, Brown Book',\n",
       " 'Young Adult Fiction',\n",
       " '19',\n",
       " 'Lovely Bones,The',\n",
       " 'Sebold, Alice',\n",
       " '2,005,598',\n",
       " 'Pan Macmillan',\n",
       " 'General & Literary Fiction',\n",
       " '20',\n",
       " 'Curious Incident of the Dog in the Night-time,The',\n",
       " 'Haddon, Mark',\n",
       " '1,979,552',\n",
       " 'Random House',\n",
       " 'General & Literary Fiction',\n",
       " '21',\n",
       " 'Digital Fortress',\n",
       " 'Brown, Dan',\n",
       " '1,928,900',\n",
       " 'Transworld',\n",
       " 'Crime, Thriller & Adventure',\n",
       " '22',\n",
       " 'Short History of Nearly Everything,A',\n",
       " 'Bryson, Bill',\n",
       " '1,852,919',\n",
       " 'Transworld',\n",
       " 'Popular Science',\n",
       " '23',\n",
       " 'Girl Who Played with Fire,The:Millennium Trilogy',\n",
       " 'Larsson, Stieg',\n",
       " '1,814,784',\n",
       " 'Quercus',\n",
       " 'Crime, Thriller & Adventure',\n",
       " '24',\n",
       " 'Breaking Dawn',\n",
       " 'Meyer, Stephenie',\n",
       " '1,787,118',\n",
       " 'Little, Brown Book',\n",
       " 'Young Adult Fiction',\n",
       " '25',\n",
       " 'Very Hungry Caterpillar,The:The Very Hungry Caterpillar',\n",
       " 'Carle, Eric',\n",
       " '1,783,535',\n",
       " 'Penguin',\n",
       " 'Picture Books',\n",
       " '26',\n",
       " 'Gruffalo,The',\n",
       " 'Donaldson, Julia',\n",
       " '1,781,269',\n",
       " 'Pan Macmillan',\n",
       " 'Picture Books',\n",
       " '27',\n",
       " \"Jamie's 30-Minute Meals\",\n",
       " 'Oliver, Jamie',\n",
       " '1,743,266',\n",
       " 'Penguin',\n",
       " 'Food & Drink: General',\n",
       " '28',\n",
       " 'Kite Runner,The',\n",
       " 'Hosseini, Khaled',\n",
       " '1,629,119',\n",
       " 'Bloomsbury',\n",
       " 'General & Literary Fiction',\n",
       " '29',\n",
       " 'One Day',\n",
       " 'Nicholls, David',\n",
       " '1,616,068',\n",
       " 'Hodder & Stoughton',\n",
       " 'General & Literary Fiction',\n",
       " '30',\n",
       " 'Thousand Splendid Suns,A',\n",
       " 'Hosseini, Khaled',\n",
       " '1,583,992',\n",
       " 'Bloomsbury',\n",
       " 'General & Literary Fiction',\n",
       " '31',\n",
       " \"Girl Who Kicked the Hornets' Nest,The:Millennium Trilogy\",\n",
       " 'Larsson, Stieg',\n",
       " '1,555,135',\n",
       " 'Quercus',\n",
       " 'Crime, Thriller & Adventure',\n",
       " '32',\n",
       " \"Time Traveler's Wife,The\",\n",
       " 'Niffenegger, Audrey',\n",
       " '1,546,886',\n",
       " 'Random House',\n",
       " 'General & Literary Fiction',\n",
       " '33',\n",
       " 'Atonement',\n",
       " 'McEwan, Ian',\n",
       " '1,539,428',\n",
       " 'Random House',\n",
       " 'General & Literary Fiction',\n",
       " '34',\n",
       " \"Bridget Jones's Diary:A Novel\",\n",
       " 'Fielding, Helen',\n",
       " '1,508,205',\n",
       " 'Pan Macmillan',\n",
       " 'General & Literary Fiction',\n",
       " '35',\n",
       " 'World According to Clarkson,The',\n",
       " 'Clarkson, Jeremy',\n",
       " '1,489,403',\n",
       " 'Penguin',\n",
       " 'Humour: Collections & General',\n",
       " '36',\n",
       " \"Captain Corelli's Mandolin\",\n",
       " 'Bernieres, Louis de',\n",
       " '1,352,318',\n",
       " 'Random House',\n",
       " 'General & Literary Fiction',\n",
       " '37',\n",
       " 'Sound of Laughter,The',\n",
       " 'Kay, Peter',\n",
       " '1,310,207',\n",
       " 'Random House',\n",
       " 'Autobiography: General',\n",
       " '38',\n",
       " 'Life of Pi',\n",
       " 'Martel, Yann',\n",
       " '1,310,176',\n",
       " 'Canongate',\n",
       " 'General & Literary Fiction',\n",
       " '39',\n",
       " 'Billy Connolly',\n",
       " 'Stephenson, Pamela',\n",
       " '1,231,957',\n",
       " 'HarperCollins',\n",
       " 'Biography: The Arts',\n",
       " '40',\n",
       " 'Child Called It,A',\n",
       " 'Pelzer, Dave',\n",
       " '1,217,712',\n",
       " 'Orion',\n",
       " 'Autobiography: General',\n",
       " '41',\n",
       " \"Gruffalo's Child,The\",\n",
       " 'Donaldson, Julia',\n",
       " '1,208,711',\n",
       " 'Pan Macmillan',\n",
       " 'Picture Books',\n",
       " '42',\n",
       " \"Angela's Ashes:A Memoir of a Childhood\",\n",
       " 'McCourt, Frank',\n",
       " '1,204,058',\n",
       " 'HarperCollins',\n",
       " 'Autobiography: General',\n",
       " '43',\n",
       " 'Birdsong',\n",
       " 'Faulks, Sebastian',\n",
       " '1,184,967',\n",
       " 'Random House',\n",
       " 'General & Literary Fiction',\n",
       " '44',\n",
       " 'Northern Lights:His Dark Materials S.',\n",
       " 'Pullman, Philip',\n",
       " '1,181,503',\n",
       " 'Scholastic Ltd.',\n",
       " 'Young Adult Fiction',\n",
       " '45',\n",
       " 'Labyrinth',\n",
       " 'Mosse, Kate',\n",
       " '1,181,093',\n",
       " 'Orion',\n",
       " 'General & Literary Fiction',\n",
       " '46',\n",
       " 'Harry Potter and the Half-blood Prince',\n",
       " 'Rowling, J.K.',\n",
       " '1,153,181',\n",
       " 'Bloomsbury',\n",
       " 'Science Fiction & Fantasy',\n",
       " '47',\n",
       " 'Help,The',\n",
       " 'Stockett, Kathryn',\n",
       " '1,132,336',\n",
       " 'Penguin',\n",
       " 'General & Literary Fiction',\n",
       " '48',\n",
       " 'Man and Boy',\n",
       " 'Parsons, Tony',\n",
       " '1,130,802',\n",
       " 'HarperCollins',\n",
       " 'General & Literary Fiction',\n",
       " '49',\n",
       " 'Memoirs of a Geisha',\n",
       " 'Golden, Arthur',\n",
       " '1,126,337',\n",
       " 'Random House',\n",
       " 'General & Literary Fiction',\n",
       " '50',\n",
       " \"No.1 Ladies' Detective Agency,The:No.1 Ladies' Detective Agency S.\",\n",
       " 'McCall Smith, Alexander',\n",
       " '1,115,549',\n",
       " 'Little, Brown Book',\n",
       " 'Crime, Thriller & Adventure',\n",
       " '51',\n",
       " 'Island,The',\n",
       " 'Hislop, Victoria',\n",
       " '1,108,328',\n",
       " 'Headline',\n",
       " 'General & Literary Fiction',\n",
       " '52',\n",
       " 'PS, I Love You',\n",
       " 'Ahern, Cecelia',\n",
       " '1,107,379',\n",
       " 'HarperCollins',\n",
       " 'General & Literary Fiction',\n",
       " '53',\n",
       " 'You are What You Eat:The Plan That Will Change Your Life',\n",
       " 'McKeith, Gillian',\n",
       " '1,104,403',\n",
       " 'Penguin',\n",
       " 'Fitness & Diet',\n",
       " '54',\n",
       " 'Shadow of the Wind,The',\n",
       " 'Zafon, Carlos Ruiz',\n",
       " '1,092,349',\n",
       " 'Orion',\n",
       " 'General & Literary Fiction',\n",
       " '55',\n",
       " 'Tales of Beedle the Bard,The',\n",
       " 'Rowling, J.K.',\n",
       " '1,090,847',\n",
       " 'Bloomsbury',\n",
       " \"Children's Fiction\",\n",
       " '56',\n",
       " 'Broker,The',\n",
       " 'Grisham, John',\n",
       " '1,087,262',\n",
       " 'Random House',\n",
       " 'Crime, Thriller & Adventure',\n",
       " '57',\n",
       " \"Dr. Atkins' New Diet Revolution:The No-hunger, Luxurious Weight Loss P\",\n",
       " 'Atkins, Robert C.',\n",
       " '1,054,196',\n",
       " 'Random House',\n",
       " 'Fitness & Diet',\n",
       " '58',\n",
       " 'Subtle Knife,The:His Dark Materials S.',\n",
       " 'Pullman, Philip',\n",
       " '1,037,160',\n",
       " 'Scholastic Ltd.',\n",
       " 'Young Adult Fiction',\n",
       " '59',\n",
       " 'Eats, Shoots and Leaves:The Zero Tolerance Approach to Punctuation',\n",
       " 'Truss, Lynne',\n",
       " '1,023,688',\n",
       " 'Profile Books Group',\n",
       " 'Usage & Writing Guides',\n",
       " '60',\n",
       " \"Delia's How to Cook:(Bk.1)\",\n",
       " 'Smith, Delia',\n",
       " '1,015,956',\n",
       " 'Random House',\n",
       " 'Food & Drink: General',\n",
       " '61',\n",
       " 'Chocolat',\n",
       " 'Harris, Joanne',\n",
       " '1,009,873',\n",
       " 'Transworld',\n",
       " 'General & Literary Fiction',\n",
       " '62',\n",
       " 'Boy in the Striped Pyjamas,The',\n",
       " 'Boyne, John',\n",
       " '1,004,414',\n",
       " 'Random House Childrens Books G',\n",
       " 'Young Adult Fiction',\n",
       " '63',\n",
       " \"My Sister's Keeper\",\n",
       " 'Picoult, Jodi',\n",
       " '1,003,780',\n",
       " 'Hodder & Stoughton',\n",
       " 'General & Literary Fiction',\n",
       " '64',\n",
       " 'Amber Spyglass,The:His Dark Materials S.',\n",
       " 'Pullman, Philip',\n",
       " '1,002,314',\n",
       " 'Scholastic Ltd.',\n",
       " 'Young Adult Fiction',\n",
       " '65',\n",
       " 'To Kill a Mockingbird',\n",
       " 'Lee, Harper',\n",
       " '998,213',\n",
       " 'Random House',\n",
       " 'General & Literary Fiction',\n",
       " '66',\n",
       " 'Men are from Mars, Women are from Venus:A Practical Guide for Improvin',\n",
       " 'Gray, John',\n",
       " '992,846',\n",
       " 'HarperCollins',\n",
       " 'Popular Culture & Media: General Interest',\n",
       " '67',\n",
       " 'Dear Fatty',\n",
       " 'French, Dawn',\n",
       " '986,753',\n",
       " 'Random House',\n",
       " 'Autobiography: The Arts',\n",
       " '68',\n",
       " 'Short History of Tractors in Ukrainian,A',\n",
       " 'Lewycka, Marina',\n",
       " '986,115',\n",
       " 'Penguin',\n",
       " 'General & Literary Fiction',\n",
       " '69',\n",
       " 'Hannibal',\n",
       " 'Harris, Thomas',\n",
       " '970,509',\n",
       " 'Random House',\n",
       " 'Crime, Thriller & Adventure',\n",
       " '70',\n",
       " 'Lord of the Rings,The',\n",
       " 'Tolkien, J. R. R.',\n",
       " '967,466',\n",
       " 'HarperCollins',\n",
       " 'Science Fiction & Fantasy',\n",
       " '71',\n",
       " 'Stupid White Men:...and Other Sorry Excuses for the State of the Natio',\n",
       " 'Moore, Michael',\n",
       " '963,353',\n",
       " 'Penguin',\n",
       " 'Current Affairs & Issues',\n",
       " '72',\n",
       " 'Interpretation of Murder,The',\n",
       " 'Rubenfeld, Jed',\n",
       " '962,515',\n",
       " 'Headline',\n",
       " 'Crime, Thriller & Adventure',\n",
       " '73',\n",
       " 'Sharon Osbourne Extreme:My Autobiography',\n",
       " 'Osbourne, Sharon',\n",
       " '959,496',\n",
       " 'Little, Brown Book',\n",
       " 'Autobiography: The Arts',\n",
       " '74',\n",
       " 'Alchemist,The:A Fable About Following Your Dream',\n",
       " 'Coelho, Paulo',\n",
       " '956,114',\n",
       " 'HarperCollins',\n",
       " 'General & Literary Fiction',\n",
       " '75',\n",
       " \"At My Mother's Knee ...:and Other Low Joints\",\n",
       " \"O'Grady, Paul\",\n",
       " '945,640',\n",
       " 'Transworld',\n",
       " 'Autobiography: The Arts',\n",
       " '76',\n",
       " 'Notes from a Small Island',\n",
       " 'Bryson, Bill',\n",
       " '931,312',\n",
       " 'Transworld',\n",
       " 'Travel Writing',\n",
       " '77',\n",
       " 'Return of the Naked Chef,The',\n",
       " 'Oliver, Jamie',\n",
       " '925,425',\n",
       " 'Penguin',\n",
       " 'Food & Drink: General',\n",
       " '78',\n",
       " 'Bridget Jones: The Edge of Reason',\n",
       " 'Fielding, Helen',\n",
       " '924,695',\n",
       " 'Pan Macmillan',\n",
       " 'General & Literary Fiction',\n",
       " '79',\n",
       " \"Jamie's Italy\",\n",
       " 'Oliver, Jamie',\n",
       " '906,968',\n",
       " 'Penguin',\n",
       " 'National & Regional Cuisine',\n",
       " '80',\n",
       " 'I Can Make You Thin',\n",
       " 'McKenna, Paul',\n",
       " '905,086',\n",
       " 'Transworld',\n",
       " 'Fitness & Diet',\n",
       " '81',\n",
       " 'Down Under',\n",
       " 'Bryson, Bill',\n",
       " '890,847',\n",
       " 'Transworld',\n",
       " 'Travel Writing',\n",
       " '82',\n",
       " 'Summons,The',\n",
       " 'Grisham, John',\n",
       " '869,671',\n",
       " 'Random House',\n",
       " 'Crime, Thriller & Adventure',\n",
       " '83',\n",
       " 'Small Island',\n",
       " 'Levy, Andrea',\n",
       " '869,659',\n",
       " 'Headline',\n",
       " 'General & Literary Fiction',\n",
       " '84',\n",
       " 'Nigella Express',\n",
       " 'Lawson, Nigella',\n",
       " '862,602',\n",
       " 'Random House',\n",
       " 'Food & Drink: General',\n",
       " '85',\n",
       " 'Brick Lane',\n",
       " 'Ali, Monica',\n",
       " '856,540',\n",
       " 'Transworld',\n",
       " 'General & Literary Fiction',\n",
       " '86',\n",
       " \"Memory Keeper's Daughter,The\",\n",
       " 'Edwards, Kim',\n",
       " '845,858',\n",
       " 'Penguin',\n",
       " 'General & Literary Fiction',\n",
       " '87',\n",
       " 'Room on the Broom',\n",
       " 'Donaldson, Julia',\n",
       " '842,535',\n",
       " 'Pan Macmillan',\n",
       " 'Picture Books',\n",
       " '88',\n",
       " 'About a Boy',\n",
       " 'Hornby, Nick',\n",
       " '828,215',\n",
       " 'Penguin',\n",
       " 'General & Literary Fiction',\n",
       " '89',\n",
       " 'My Booky Wook',\n",
       " 'Brand, Russell',\n",
       " '820,563',\n",
       " 'Hodder & Stoughton',\n",
       " 'Autobiography: The Arts',\n",
       " '90',\n",
       " 'God Delusion,The',\n",
       " 'Dawkins, Richard',\n",
       " '816,907',\n",
       " 'Transworld',\n",
       " 'Popular Science',\n",
       " '91',\n",
       " '\"Beano\" Annual,The',\n",
       " '0',\n",
       " '816,585',\n",
       " 'D.C. Thomson',\n",
       " \"Children's Annuals\",\n",
       " '92',\n",
       " 'White Teeth',\n",
       " 'Smith, Zadie',\n",
       " '815,586',\n",
       " 'Penguin',\n",
       " 'General & Literary Fiction',\n",
       " '93',\n",
       " 'House at Riverton,The',\n",
       " 'Morton, Kate',\n",
       " '814,370',\n",
       " 'Pan Macmillan',\n",
       " 'General & Literary Fiction',\n",
       " '94',\n",
       " 'Book Thief,The',\n",
       " 'Zusak, Markus',\n",
       " '809,641',\n",
       " 'Transworld',\n",
       " 'General & Literary Fiction',\n",
       " '95',\n",
       " 'Nights of Rain and Stars',\n",
       " 'Binchy, Maeve',\n",
       " '808,900',\n",
       " 'Orion',\n",
       " 'General & Literary Fiction',\n",
       " '96',\n",
       " 'Ghost,The',\n",
       " 'Harris, Robert',\n",
       " '807,311',\n",
       " 'Random House',\n",
       " 'General & Literary Fiction',\n",
       " '97',\n",
       " 'Happy Days with the Naked Chef',\n",
       " 'Oliver, Jamie',\n",
       " '794,201',\n",
       " 'Penguin',\n",
       " 'Food & Drink: General',\n",
       " '98',\n",
       " 'Hunger Games,The:Hunger Games Trilogy',\n",
       " 'Collins, Suzanne',\n",
       " '792,187',\n",
       " 'Scholastic Ltd.',\n",
       " 'Young Adult Fiction',\n",
       " '99',\n",
       " \"Lost Boy,The:A Foster Child's Search for the Love of a Family\",\n",
       " 'Pelzer, Dave',\n",
       " '791,507',\n",
       " 'Orion',\n",
       " 'Biography: General',\n",
       " '100',\n",
       " \"Jamie's Ministry of Food:Anyone Can Learn to Cook in 24 Hours\",\n",
       " 'Oliver, Jamie',\n",
       " '791,095',\n",
       " 'Penguin',\n",
       " 'Food & Drink: General']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scrapping \n",
    "Lists=[]\n",
    "lists=driver.find_elements_by_xpath(\"//table[@class='in-article sortable']//tbody//tr//td\")\n",
    "for i in lists:\n",
    "    try:\n",
    "        Lists.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Lists.append('-')        \n",
    "Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>VolumeSales</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index                                              Title            Author  \\\n",
       "0      1                                  Da Vinci Code,The        Brown, Dan   \n",
       "1      2               Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2      3           Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3      4          Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4      5                               Fifty Shades of Grey      James, E. L.   \n",
       "..   ...                                                ...               ...   \n",
       "95    96                                          Ghost,The    Harris, Robert   \n",
       "96    97                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97    98              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98    99  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99   100  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   VolumeSales        Publisher                        Genre  \n",
       "0    5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1    4,475,152       Bloomsbury           Children's Fiction  \n",
       "2    4,200,654       Bloomsbury           Children's Fiction  \n",
       "3    4,179,479       Bloomsbury           Children's Fiction  \n",
       "4    3,758,936     Random House              Romance & Sagas  \n",
       "..         ...              ...                          ...  \n",
       "95     807,311     Random House   General & Literary Fiction  \n",
       "96     794,201          Penguin        Food & Drink: General  \n",
       "97     792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98     791,507            Orion           Biography: General  \n",
       "99     791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Index=[]\n",
    "Title=[]\n",
    "Author=[]\n",
    "VolumeSales=[]\n",
    "Publisher=[]\n",
    "Genre=[]\n",
    "\n",
    "#Index\n",
    "for i in range(0,len(Lists),6):\n",
    "    try:\n",
    "        Index.append(Lists[i])\n",
    "    except NoSuchElementException:\n",
    "        Index.append('-')\n",
    "\n",
    "        \n",
    "#Title\n",
    "for i in range(1,len(Lists),6):\n",
    "    try:\n",
    "        Title.append(Lists[i])\n",
    "    except NoSuchElementException:\n",
    "        Title.append('-')    \n",
    "\n",
    "#Author\n",
    "for i in range(2,len(Lists),6):\n",
    "    Author.append(Lists[i])\n",
    "\n",
    "    \n",
    "#VolumeSales\n",
    "try:\n",
    "    for i in range(3,len(Lists),6):\n",
    "        VolumeSales.append(Lists[i])\n",
    "except NoSuchElementException:\n",
    "        VolumeSales.append('-')\n",
    "\n",
    "#Publisher\n",
    "try:\n",
    "    for i in range(4,len(Lists),6):\n",
    "        Publisher.append(Lists[i])\n",
    "except NoSuchElementException:\n",
    "        Publisher.append('-')\n",
    "        \n",
    "#Genre\n",
    "try:\n",
    "    for i in range(5,len(Lists),6):\n",
    "        Genre.append(Lists[i])\n",
    "except NoSuchElementException:\n",
    "        Genre.append('-')\n",
    "   \n",
    "\n",
    "df=pd.DataFrame({'Index':Index,'Title':Title,'Author':Author,'VolumeSales':VolumeSales,'Publisher':Publisher,'Genre':Genre})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape the details most watched tv series of all time from imdb.com.\n",
    "\n",
    " Url = https://www.imdb.com/list/ls095964455/\n",
    " \n",
    "You have to find the following details:\n",
    "\n",
    "A) Name\n",
    "\n",
    "B) Year span\n",
    "\n",
    "C) Genre\n",
    "\n",
    "D) Run time\n",
    "\n",
    "E) Ratings\n",
    "\n",
    "F) Votes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opning ibmd.com\n",
    "driver.get(' https://www.imdb.com/list/ls095964455/')\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Name=[]\n",
    "Range_Year=[]\n",
    "RunTime=[]\n",
    "StarRating=[]\n",
    "Genre=[]\n",
    "\n",
    "\n",
    "#Name\n",
    "name=driver.find_elements_by_xpath(\"//h3[@class='lister-item-header']//a\")\n",
    "for i in name:\n",
    "    try:\n",
    "        Name.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Name.append('-')  \n",
    "        \n",
    "\n",
    "#scrapping range\n",
    "Lists1=[]\n",
    "lists1=driver.find_elements_by_xpath(\"//h3[@class='lister-item-header']//span\")\n",
    "for i in lists1:\n",
    "    try:\n",
    "        Lists1.append(i.text.split())\n",
    "    except NoSuchElementException:\n",
    "        Lists1.append('-')        \n",
    "\n",
    "try:\n",
    "    for i in range(1,len(Lists1),2):\n",
    "        Range_Year.append(Lists1[i])\n",
    "except NoSuchElementException:\n",
    "        Range_Year.append('-')\n",
    "        \n",
    "#Genre\n",
    "genre=driver.find_elements_by_xpath(\"//span[@class='genre']\")\n",
    "for i in genre:\n",
    "    try:\n",
    "        Genre.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Genre.append('-') \n",
    "\n",
    "#RunTime\n",
    "runTime=driver.find_elements_by_xpath(\"//span[@class='runtime']\")\n",
    "for i in runTime:\n",
    "    try:\n",
    "        RunTime.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        RunTime.append('-') \n",
    "        \n",
    "#RunTime\n",
    "starRating=driver.find_elements_by_xpath(\"//span[@class='ipl-rating-star__star']//span\")\n",
    "for i in runTime:\n",
    "    try:\n",
    "        StarRating.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        StarRating.append('-') \n",
    "\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of Name 100\n",
      "length of Range_Year 100\n",
      "length of Genre 100\n",
      "length of RunTime 100\n"
     ]
    }
   ],
   "source": [
    "print(\"length of Name\",len(Name))\n",
    "print(\"length of Range_Year\",len(Range_Year))\n",
    "print(\"length of Genre\",len(Genre))\n",
    "print(\"length of RunTime\",len(RunTime))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>RunTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>[(2011–2019)]</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>[(2016–, )]</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>[(2010–2022)]</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>[(2017–2020)]</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>[(2014–2020)]</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>[(2013–2017)]</td>\n",
       "      <td>Drama, Fantasy</td>\n",
       "      <td>42 min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>[(2017–2019)]</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>[(2005–2020)]</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>[(2015–2019)]</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>[(2018)]</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name      Year Span                     Genre  \\\n",
       "0                  Game of Thrones  [(2011–2019)]  Action, Adventure, Drama   \n",
       "1                  Stranger Things    [(2016–, )]    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  [(2010–2022)]   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  [(2017–2020)]  Drama, Mystery, Thriller   \n",
       "4                          The 100  [(2014–2020)]    Drama, Mystery, Sci-Fi   \n",
       "..                             ...            ...                       ...   \n",
       "95                           Reign  [(2013–2017)]            Drama, Fantasy   \n",
       "96  A Series of Unfortunate Events  [(2017–2019)]  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds  [(2005–2020)]     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  [(2015–2019)]      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       [(2018)]    Drama, Horror, Mystery   \n",
       "\n",
       "    RunTime  \n",
       "0    57 min  \n",
       "1    51 min  \n",
       "2    44 min  \n",
       "3    60 min  \n",
       "4    43 min  \n",
       "..      ...  \n",
       "95   42 min  \n",
       "96   50 min  \n",
       "97   42 min  \n",
       "98   45 min  \n",
       "99  572 min  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Name':Name,'Year Span':Range_Year,'Genre':Genre,'RunTime':RunTime})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Details of Datasets from UCI machine learning repositories.\n",
    "\n",
    " Url = https://archive.ics.uci.edu/\n",
    " \n",
    " You have to find the following details:\n",
    " \n",
    "A) Dataset name\n",
    "\n",
    "B) Data type\n",
    "\n",
    "C) Task\n",
    "\n",
    "D) Attribute type\n",
    "\n",
    "E) No of instances\n",
    "\n",
    "F) No of attribute\n",
    "\n",
    "G) Year\n",
    "\n",
    "Note: - from the home page you have to go to the Show All Dataset page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opning archive.ics.uci.edu\n",
    "driver.get('https://archive.ics.uci.edu/')\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking the view all dataset\n",
    "search_button=driver.find_element_by_xpath(\"/html/body/table[1]/tbody/tr/td[2]/span[2]/a/font/b\")\n",
    "search_button.click()\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"edf4f38af3c000e877c30d1b0140a1b0\", element=\"e2a73192-9202-423d-964d-2f1f016999db\")>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting into the second tr \n",
    "#scrapping range\n",
    "Lists=[]\n",
    "list=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]\")\n",
    "list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Name=[]\n",
    "Datatype=[]\n",
    "DefaultTask=[]\n",
    "AttributeTypes=[]\n",
    "\n",
    "for i in list:\n",
    "    try:\n",
    "        Lists.append(i.text.split())\n",
    "    except NoSuchElementException:\n",
    "        Lists.append('-') \n",
    "        \n",
    "for i in range(0,len(Lists),6):\n",
    "        Name.append(Lists[i])\n",
    "        \n",
    "for i in range(1,len(Lists),6):\n",
    "        Datatype.append(Lists[i])\n",
    "        \n",
    "for i in range(2,len(Lists),6):\n",
    "        DefaultTask.append(Lists[i])\n",
    "        \n",
    "for i in range(3,len(Lists),6):\n",
    "        Datatype.append(Lists[i])\n",
    "        \n",
    "for i in range(4,len(Lists),6):\n",
    "        Datatype.append(Lists[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
