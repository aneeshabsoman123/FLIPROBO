{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\91890\\anaconda3\\lib\\site-packages (3.141.0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.3.3; however, version 21.1.3 is available.\n",
      "You should consider upgrading via the 'c:\\users\\91890\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: urllib3 in c:\\users\\91890\\anaconda3\\lib\\site-packages (from selenium) (1.25.11)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a python program to scrape data for “Data Analyst” Job position in\n",
    "“Bangalore” location. You have to scrape the job-title, job-location, company_name,\n",
    "experience_required. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill,Designations,Companies” field and enter “Bangalore”\n",
    "in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note- All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.naukri.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"6e42025ae4d80c1858af31f928644113\", element=\"78e983f3-0368-4dd2-acc1-4a874d01b728\")>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_job=driver.find_element_by_xpath('//input[@class=\"sugInp\"]')\n",
    "search_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter “Data Analyst” in “Skill,Designations,Companies” field and \n",
    "\n",
    "search_job.send_keys(\"Data Analyst\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#enter “Bangalore” in “enter the location” field.\n",
    "search_loc=driver.find_element_by_id('qsb-location-sugg')\n",
    "search_loc.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#click the search button\n",
    "search_btn=driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"6e42025ae4d80c1858af31f928644113\", element=\"8e3e15a1-1e27-4874-98ad-6d2b73618f2e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"6e42025ae4d80c1858af31f928644113\", element=\"c8540b64-aa19-4b46-b2f2-03fe6bc4cdcb\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"6e42025ae4d80c1858af31f928644113\", element=\"bf3a7a11-6ffb-4a78-8667-878fd40ad0b3\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"6e42025ae4d80c1858af31f928644113\", element=\"7ac539ef-8be0-43c0-bbaa-e6b7c3264ed9\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"6e42025ae4d80c1858af31f928644113\", element=\"7e885114-d5b6-4ea8-8293-b42f80e7ec15\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"6e42025ae4d80c1858af31f928644113\", element=\"0c5857fd-9ab1-44e3-b468-4f4b6e16e90a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"6e42025ae4d80c1858af31f928644113\", element=\"14b9bfca-3c29-4797-9c83-3845052b31c4\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"6e42025ae4d80c1858af31f928644113\", element=\"286d14b0-8625-40e4-a00f-7f71cc89efe4\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"6e42025ae4d80c1858af31f928644113\", element=\"4b039b88-9ed3-4b55-9e8c-9b054a06b968\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"6e42025ae4d80c1858af31f928644113\", element=\"2d87498f-1d3e-49f9-be0f-2ca8f014211b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"6e42025ae4d80c1858af31f928644113\", element=\"4851f96f-a76a-49e7-b7ba-57f390a1e53a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"6e42025ae4d80c1858af31f928644113\", element=\"9b7b70fa-8e1c-48cb-84dc-5f947883e028\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"6e42025ae4d80c1858af31f928644113\", element=\"d4bb1360-4753-478d-9b67-363e6c8fe9d8\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"6e42025ae4d80c1858af31f928644113\", element=\"7790c85e-4a87-471b-a867-9d6801ee7cfe\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"6e42025ae4d80c1858af31f928644113\", element=\"bd4c925a-6a90-4319-8fd6-70955c24d1ae\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"6e42025ae4d80c1858af31f928644113\", element=\"27aa7aaa-a465-4a22-a3a9-81e3c6038057\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"6e42025ae4d80c1858af31f928644113\", element=\"7f556c6e-c925-43ca-b62d-0dbac85165a8\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"6e42025ae4d80c1858af31f928644113\", element=\"c44ff5d2-fdd8-4e80-89a3-c54474560756\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"6e42025ae4d80c1858af31f928644113\", element=\"0c603056-cf87-445e-9275-727387cd28e5\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"6e42025ae4d80c1858af31f928644113\", element=\"d2f80916-d4a8-4c5b-957e-fc4686d3a4d9\")>]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scrape the data for the first 10 jobs results you get.\n",
    "\n",
    "\n",
    "#job title\n",
    "alltitle=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "alltitle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Senior Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst (Data Stewards)//Immediate Joiners//Bangalore',\n",
       " 'Data Analyst with Replicon Software',\n",
       " 'Data Analyst / Sr. Data Analyst - SQL',\n",
       " 'Senior Data Analyst',\n",
       " 'Senior Data Analyst',\n",
       " 'Senior Data Analyst',\n",
       " 'Senior Associate - Data Analyst',\n",
       " 'Senior Associate - Data Analyst',\n",
       " 'Data Analyst-Immediate Joiners',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Senior Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Sr Data Analyst with Hadoop and Alteryx both are Mandate_MNC Company',\n",
       " 'Senior Data Analyst',\n",
       " 'Immediate job openings For Partner Consultant - Sizing(Data Analyst) ',\n",
       " 'Data Analyst, Component Engineering']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_titles=[]\n",
    "for i in alltitle:\n",
    "    job_titles.append(i.text)\n",
    "\n",
    "job_titles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Flipkart Internet Private Limited',\n",
       " 'Zilingo.com',\n",
       " 'Tech Mahindra Ltd.',\n",
       " 'Replicon Software (India) Pvt Ltd',\n",
       " 'Naukri Premium - Employer Services',\n",
       " 'Publicis Groupe',\n",
       " 'Publicis Groupe',\n",
       " 'Publicis Groupe',\n",
       " 'Sapient',\n",
       " 'Publicis Groupe',\n",
       " 'Brillio',\n",
       " 'COLLABERA',\n",
       " 'Allegis Services India Pvt. Ltd.',\n",
       " 'Allegis Services India Pvt. Ltd.',\n",
       " 'Flipkart Internet Private Limited',\n",
       " 'ANZ Banking Group',\n",
       " 'Inspiration Manpower Consultancy Pvt. Ltd.',\n",
       " 'Liventus, Inc.',\n",
       " 'RANDSTAD INDIA PVT LTD',\n",
       " 'Rockwell Automation']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#company\n",
    "companies_tags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "\n",
    "\n",
    "companies_tags_titles=[]\n",
    "for i in companies_tags:\n",
    "    companies_tags_titles.append(i.text)\n",
    "    \n",
    "companies_tags_titles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4-5 Yrs',\n",
       " '0-4 Yrs',\n",
       " '5-10 Yrs',\n",
       " '2-4 Yrs',\n",
       " '2-5 Yrs',\n",
       " '5-9 Yrs',\n",
       " '6-8 Yrs',\n",
       " '1-7 Yrs',\n",
       " '4-6 Yrs',\n",
       " '1-3 Yrs',\n",
       " '4-6 Yrs',\n",
       " '2-4 Yrs',\n",
       " '5-8 Yrs',\n",
       " '8-12 Yrs',\n",
       " '2-5 Yrs',\n",
       " '3-8 Yrs',\n",
       " '7-12 Yrs',\n",
       " '5-8 Yrs',\n",
       " '1-5 Yrs',\n",
       " '2-3 Yrs']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#experience\n",
    "experience_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']//span\")\n",
    "\n",
    "\n",
    "experience_tags_titles=[]\n",
    "for i in experience_tags:\n",
    "    experience_tags_titles.append(i.text)\n",
    "experience_tags_titles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru(2nd Phase JP Nagar)',\n",
       " 'Bangalore/Bengaluru(Marathahalli)',\n",
       " 'Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#location\n",
    "location_title=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']//span\")\n",
    "\n",
    "location_tags_titles=[]\n",
    "for i in location_title:\n",
    "    location_tags_titles.append(i.text)\n",
    "    \n",
    "location_tags_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " '3,75,000 - 6,00,000 PA.',\n",
       " '4,50,000 - 5,50,000 PA.',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " '10,00,000 - 20,00,000 PA.',\n",
       " '1,50,000 - more than 3,00,000 PA.',\n",
       " 'Not disclosed']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#salary\n",
    "salary_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi salary']//span\")\n",
    "\n",
    "\n",
    "salary_tags_titles=[]\n",
    "for i in salary_tags:\n",
    "    salary_tags_titles.append(i.text)\n",
    "salary_tags_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>experience</th>\n",
       "      <th>salary</th>\n",
       "      <th>place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "      <td>4-5 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Zilingo.com</td>\n",
       "      <td>0-4 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst (Data Stewards)//Immediate Joiner...</td>\n",
       "      <td>Tech Mahindra Ltd.</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst with Replicon Software</td>\n",
       "      <td>Replicon Software (India) Pvt Ltd</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst / Sr. Data Analyst - SQL</td>\n",
       "      <td>Naukri Premium - Employer Services</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Publicis Groupe</td>\n",
       "      <td>5-9 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Publicis Groupe</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Publicis Groupe</td>\n",
       "      <td>1-7 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Associate - Data Analyst</td>\n",
       "      <td>Sapient</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Associate - Data Analyst</td>\n",
       "      <td>Publicis Groupe</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                                Senior Data Analyst   \n",
       "1                                       Data Analyst   \n",
       "2  Data Analyst (Data Stewards)//Immediate Joiner...   \n",
       "3                Data Analyst with Replicon Software   \n",
       "4              Data Analyst / Sr. Data Analyst - SQL   \n",
       "5                                Senior Data Analyst   \n",
       "6                                Senior Data Analyst   \n",
       "7                                Senior Data Analyst   \n",
       "8                    Senior Associate - Data Analyst   \n",
       "9                    Senior Associate - Data Analyst   \n",
       "\n",
       "                              company experience         salary  \\\n",
       "0   Flipkart Internet Private Limited    4-5 Yrs  Not disclosed   \n",
       "1                         Zilingo.com    0-4 Yrs  Not disclosed   \n",
       "2                  Tech Mahindra Ltd.   5-10 Yrs  Not disclosed   \n",
       "3   Replicon Software (India) Pvt Ltd    2-4 Yrs  Not disclosed   \n",
       "4  Naukri Premium - Employer Services    2-5 Yrs  Not disclosed   \n",
       "5                     Publicis Groupe    5-9 Yrs  Not disclosed   \n",
       "6                     Publicis Groupe    6-8 Yrs  Not disclosed   \n",
       "7                     Publicis Groupe    1-7 Yrs  Not disclosed   \n",
       "8                             Sapient    4-6 Yrs  Not disclosed   \n",
       "9                     Publicis Groupe    1-3 Yrs  Not disclosed   \n",
       "\n",
       "                 place  \n",
       "0  Bangalore/Bengaluru  \n",
       "1  Bangalore/Bengaluru  \n",
       "2  Bangalore/Bengaluru  \n",
       "3  Bangalore/Bengaluru  \n",
       "4  Bangalore/Bengaluru  \n",
       "5  Bangalore/Bengaluru  \n",
       "6  Bangalore/Bengaluru  \n",
       "7  Bangalore/Bengaluru  \n",
       "8  Bangalore/Bengaluru  \n",
       "9  Bangalore/Bengaluru  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "jobs=pd.DataFrame({})\n",
    "jobs['title']=job_titles[:10]\n",
    "jobs['company']=companies_tags_titles[:10]\n",
    "jobs['experience']=experience_tags_titles[:10]\n",
    "jobs['salary']=salary_tags_titles[:10]\n",
    "jobs['place']=location_tags_titles[:10]\n",
    "\n",
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobtitles=[]\n",
    "jobLocation=[]\n",
    "companyName=[]\n",
    "fulljobdesc=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first get the webpage https://www.naukri.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\chromedriver.exe\")\n",
    "url2='https://www.naukri.com/'\n",
    "driver.get(url2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter “Data Scientist” in “Skill,Designations,Companies” field and enter\n",
    "“Bangalore” in “enter the location” field.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_job2=driver.find_element_by_xpath('//input[@class=\"sugInp\"]')\n",
    "search_job2.send_keys(\"Data Scientist\")\n",
    "\n",
    "search_loc2=driver.find_element_by_id('qsb-location-sugg')\n",
    "search_loc2.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "click the search button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn=driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scrape the data for the first 10 jobs results you get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#scrape data from job openings\n",
    "\n",
    "job_opening_urls=[]\n",
    "\n",
    "url=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "\n",
    "for i in url[:10]:\n",
    "    job_opening_urls.append(i.get_attribute('href'))\n",
    "job_opening_urls\n",
    "\n",
    "\n",
    "for i in job_opening_urls:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        job_title=driver.find_elements_by_xpath(\"//h1[@class='jd-header-title']\")\n",
    "        for j in job_title:\n",
    "            jobtitles.append(j.text.replace(\"\\n\",\" \"))\n",
    "            \n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Senior Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Sr Data Scientist, Payments',\n",
       " 'Senior Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Sr Data Scientist, Payments',\n",
       " 'Senior Data Scientist']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobtitles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\chromedriver.exe\")\n",
    "url2='https://www.naukri.com/'\n",
    "driver.get(url2)\n",
    "\n",
    "search_job2=driver.find_element_by_xpath('//input[@class=\"sugInp\"]')\n",
    "search_job2.send_keys(\"Data Scientist\")\n",
    "\n",
    "driver.implicitly_wait(10)\n",
    "\n",
    "search_loc2=driver.find_element_by_id('qsb-location-sugg')\n",
    "search_loc2.send_keys(\"Bangalore\")\n",
    "\n",
    "driver.implicitly_wait(10)\n",
    "\n",
    "search_btn=driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "search_btn.click()\n",
    "\n",
    "driver.implicitly_wait(10)\n",
    "    \n",
    "#scrape data from job openings\n",
    "\n",
    "job_opening_urls=[]\n",
    "\n",
    "url=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "\n",
    "for i in url[:10]:\n",
    "    job_opening_urls.append(i.get_attribute('href'))\n",
    "job_opening_urls\n",
    "\n",
    "\n",
    "for i in job_opening_urls:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        company_name_title=driver.find_elements_by_xpath(\"//a[@class='pad-rt-8']\")\n",
    "        for k in company_name_title:\n",
    "            companyName.append(k.text.replace(\"\\n\",\" \"))\n",
    "    except:\n",
    "        pass \n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['24/7 Customer',\n",
       " '3.6(1198 Reviews)',\n",
       " '',\n",
       " '',\n",
       " 'Fractal Analytics',\n",
       " '3.9(97 Reviews)',\n",
       " '',\n",
       " '',\n",
       " 'Nielsen',\n",
       " '3.8(483 Reviews)',\n",
       " '',\n",
       " '',\n",
       " 'Wipro Limited',\n",
       " '3.8(12632 Reviews)',\n",
       " '',\n",
       " '',\n",
       " 'Pluto7',\n",
       " '',\n",
       " 'Gojek Tech',\n",
       " '',\n",
       " 'GO-JEK India',\n",
       " '4.4(5 Reviews)',\n",
       " '',\n",
       " '',\n",
       " 'Publicis Groupe',\n",
       " '3.4(64 Reviews)',\n",
       " '',\n",
       " '',\n",
       " 'AIRBNB GLOBAL CAPABILITY CENTER PRIVATE LIMITED',\n",
       " '',\n",
       " 'Lendingkart Finance Limited',\n",
       " '3.0(128 Reviews)',\n",
       " '',\n",
       " '',\n",
       " '24/7 Customer',\n",
       " '3.6(1198 Reviews)',\n",
       " '',\n",
       " '',\n",
       " 'Fractal Analytics',\n",
       " '3.9(97 Reviews)',\n",
       " '',\n",
       " '',\n",
       " 'Nielsen',\n",
       " '3.8(483 Reviews)',\n",
       " '',\n",
       " '',\n",
       " 'Wipro Limited',\n",
       " '3.8(12632 Reviews)',\n",
       " '',\n",
       " '',\n",
       " 'Pluto7',\n",
       " '',\n",
       " 'Gojek Tech',\n",
       " '',\n",
       " 'GO-JEK India',\n",
       " '4.4(5 Reviews)',\n",
       " '',\n",
       " '',\n",
       " 'Publicis Groupe',\n",
       " '3.4(64 Reviews)',\n",
       " '',\n",
       " '',\n",
       " 'AIRBNB GLOBAL CAPABILITY CENTER PRIVATE LIMITED',\n",
       " '',\n",
       " 'Lendingkart Finance Limited',\n",
       " '3.0(128 Reviews)',\n",
       " '',\n",
       " '',\n",
       " '24/7 Customer',\n",
       " '',\n",
       " 'Fractal Analytics',\n",
       " '',\n",
       " 'Nielsen',\n",
       " '',\n",
       " 'Wipro Limited',\n",
       " '',\n",
       " 'Pluto7',\n",
       " '',\n",
       " 'Gojek Tech',\n",
       " '',\n",
       " 'GO-JEK India',\n",
       " '',\n",
       " 'Publicis Groupe',\n",
       " '',\n",
       " 'AIRBNB GLOBAL CAPABILITY CENTER PRIVATE LIMITED',\n",
       " '',\n",
       " 'Lendingkart Finance Limited',\n",
       " '']"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companyName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\chromedriver.exe\")\n",
    "url2='https://www.naukri.com/'\n",
    "driver.get(url2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Not Disclosed',\n",
       " 'Not Disclosed',\n",
       " 'Not Disclosed',\n",
       " 'Not Disclosed',\n",
       " 'Not Disclosed',\n",
       " 'Not Disclosed',\n",
       " 'Not Disclosed',\n",
       " 'Not Disclosed',\n",
       " 'Not Disclosed',\n",
       " 'Not Disclosed']"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salarytitles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\chromedriver.exe\")\n",
    "url2='https://www.naukri.com/'\n",
    "driver.get(url2)\n",
    "\n",
    "search_job2=driver.find_element_by_xpath('//input[@class=\"sugInp\"]')\n",
    "search_job2.send_keys(\"Data Scientist\")\n",
    "\n",
    "driver.implicitly_wait(10)\n",
    "\n",
    "search_loc2=driver.find_element_by_id('qsb-location-sugg')\n",
    "search_loc2.send_keys(\"Bangalore\")\n",
    "\n",
    "driver.implicitly_wait(10)\n",
    "\n",
    "search_btn=driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "search_btn.click()\n",
    "\n",
    "driver.implicitly_wait(10)\n",
    "    \n",
    "#scrape data from job openings\n",
    "\n",
    "job_opening_urls=[]\n",
    "\n",
    "url=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "\n",
    "for i in url[:10]:\n",
    "    job_opening_urls.append(i.get_attribute('href'))\n",
    "job_opening_urls\n",
    "\n",
    "\n",
    "for i in job_opening_urls:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        full_job_desc=driver.find_elements_by_xpath(\"//section[@class='job-desc']\")\n",
    "        for n in full_job_desc:\n",
    "            fulljobdesc.append(n.text.replace(\"\\n\",\" \"))\n",
    "    except:\n",
    "        pass \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Job description Brief about the Role The Platforms team of the Data Science Group at [24]7.ai builds scalable AI to aid in conversational AI, agent assist solutions, and ad personalization for the Cloud. We are looking for a highly motivated and qualified data scientist to build some of our AI initiatives. This role is ideal for candidates with strong, hands-on skills in machine learning and natural language processing. Educational Qualifications: Bachelors, Master’s or PhD degree from reputed universities or institutes in one of the following disciplines: Artificial Intelligence / Machine Learning Data Science Cognitive Computing Computational Linguistics Computer Science Requirements 4+ years of experience with general purpose programming languages e.g., Python, C/C++, Java 4+ years of hands-on experience in machine learning Experience in various deep learning models, e.g., transformers, LSTMs, RNNs Experience in solving problems related to Natural Language Processing (NLP), Natural Language Understanding (NLU), and Natural Language Generation (NLG) Experience with machine learning platforms such as TensorFlow, TensorFlow Extended, PyTorch Experience building and deploying machine learning models on the Cloud (Google Cloud, Azure, AWS) Experience with production architecture of machine learning systems Good to have exposure to conversational AI, AI-based question-answering systems, AI-based compliance and monitoring systems, and ad personalization Good to have exposure to MLOps pipelines and Kubeflow Excellent communication skills Ability to collaborate cross-functionally Good presentation skills Attention to detail Responsibilities Collaborate with the Engineering and Product teams to implement machine learning models into the products and offerings of [24]7.ai Collaborate with your team members. Be responsible for implementing the machine learning models, testing them, refining them, and taking them to production Collaborate within the Data Science Group to review and refine your work to ensure the highest quality Take end-to-end ownership of AI initiatives Proactively discuss ideas for feature enhancements with the data science leadership and product leadership RoleTechnical Architect Industry TypeIT Services & Consulting Functional AreaIT Software - Other Employment TypeFull Time, Permanent Role CategoryProgramming & Design Education UG :B.Tech/BE in Computers PG :M.Tech/ME in Computers Key Skills Computer sciencedata scienceArtificial IntelligenceMachine learningLinguisticsNatural language processingNew product developmentCustomer experienceMonitoringPython',\n",
       " 'Job description The Artificial Intelligence and Machine Learning (AIML) group at Fractal Analytics is actively involved in helping Fortune 500 companies by enabling them to discover how they can leverage their data using advanced and sophisticated AI/ML algorithms for which we are looking for Data Scientists with the capability to work on independent statistical and machine learning research/ projects. If you are a problem solver with a curiosity for exploring new techniques and technologies in AIML space, then we would like to talk with you. Job Responsibilities Ability to understand a problem statement and implement analytical solutions techniques independently with independently / proactively / thought-leadership. Work with stakeholders throughout the organization to identify opportunities for leveraging company/client data to drive business solutions. Fast learner: ability to learn and pick up a new language/tool/ platform quickly. Conceptualize, design, and deliver high-quality solutions and insightful analysis. Conduct research and prototyping innovations; data and requirements gathering; solution scoping and architecture; consulting clients and client facing teams on advanced statistical and machine learning problems. Collaborate and Coordinate with different functional teams(engineering and product development) to implement models and monitor outcomes. Ability to deliver AIML based solutions around a host of domains and problems, with some of them being: Customer Segmentation Targeting, Propensity Modeling, Churn Modeling, Lifetime Value Estimation, Forecasting, Recommender Systems, Modeling Response to Incentives, Marketing Mix Optimization, Price Optimization Experience Required: Expert level proficiency in at least one of R and Python. Ability to create efficient solutions to complex problems. Strong skills in data-structures and ML algorithms. Experience of working on end-to-end data science pipeline: problem scoping, data gathering, EDA, modelling, insights, visualizations, monitoring and maintenance. Problem-solving: Ability to break the problem into small parts and applying relevant techniques to drive required outcomes. Intermediate to advanced knowledge of machine learning, probability theory, statistics, and algorithms. You will be required to discuss and use various algorithms and approaches on a daily basis. We use regression, Bayesian methods, tree-based learners, SVM, RF, XGBOOST, time series modeling, dimensionality reduction, SEM, GLM, GLMM, clustering, Deep learning etc. on a regular basis. If you know few of them you are good to go. Good to Have: Experience in one of the upcoming technologies like deep learning, NLP, image processing, recommender systems Experience of working in on one or more domains: CPG: pricing and promotion analytics, marketing analytics, trade promotions, supply chain management BFSI: cross-sell, up-sell, campaign analytics, treasury analytics, fraud detection Healthcare: medical adherence, medical risk profiling, EHR data, fraud-waste-abuse Experience in working with Linux computing environment and use of command line tools like sed/awk Good grasp on databases including RDBMS, NoSQL, MongoDB etc. Education Qualification B.Tech / M.Tech in Computer Science / Mathematics / Signal Processing or related fields. RoleTechnical Architect Industry TypeManagement Consulting Functional AreaIT Software - Application Programming, Maintenance Employment TypeFull Time, Permanent Role CategoryProgramming & Design Education UG :B.Tech/BE in Production/Industrial PG :M.Tech/ME in Electronics and Telecommunication Key Skills Supply chain managementLinuxRFRDBMSBfsiConsultingData structuresHealthcareSEMPython',\n",
       " 'Job description ABOUT THIS JOB NielsenIQ Advanced Analytics team develops and promotes a portfolio of global products. Leveraging NielsenIQs unparalleled data and global platforms, the Advanced Analytics team creates solutions to enable our clients to make better business decisions every day.  We partner with Product Owners and Core Technology Teams to build scalable, always on,  analytic products using relevant modeling/ML techniques. We’re looking for a passionate and talented Senior Data Scientist to join our growing team. In this role, you’ll have the chance to roll up your sleeves and apply data science methods and analytics to sustain NielsenIQ Analytics growth. Successful candidates are intellectually curious builders and active learners who are biased toward action, new problem solving. Roles & Responsibilities : Understand business issues, stakeholder requirement and expectations Perform relevant modeling analysis and POC exploring multiple techniques Ensure Analytics model quality Document and present findings and recommendations on methodology in a structured way to various stakeholder or partnering teams (Engineering, Tech, Product leader). Work closely with the Engineering and Tech team to convert those POC into fully scalable products. Active and effective collaboration with other project team members (other Data Scientist, Data Steward, Technology Engineer) Collaboratively manage projects from timeline creation to project completion, managing expectations with leaders and colleagues Encourage team building, best practices sharing especially with more junior team members. Stay abreast of developments in the area to ensure bringing the most appropriate solutions to our business About You You’ve built a decent track record in research and data analytics. And you have the communication chops to translate it all into conversations. While you’ve worked with global cross-functional teams, you can also put your head down and focus on independent projects. Seeing the big picture takes attention to detail. Keeping up with the fast-changing world of technology takes someone who recognizes that. You know what’s happening in big data and you’re ready to influence what’s next. Qualifications Masters degree in Data Sciences, mathematics or a closely related field 3 to 5 years of experience as a Data Scientist in the business Strong knowledge of statistical modelling, machine learning. Experience in machine learning, supervised and unsupervised: Forecasting, Classification, Data/Text Mining, NLP, Decision Trees, Adaptive Decision Algorithms, Random Forest, Search Algorithms, Neural Networks, Deep Learning Algorithms Experience with Optimisation techniques: linear programming, integer programming, genetic algorithm, constrained optimisation Experience in working on distributed or cloud computing platforms such as Google Cloud or Microsoft Azure Proficiency in Data Science coding languages like Python, PySpark, SQL, R in a cloud environment like DataBricks Experience using collaborative development tools (git). Experience working with Agile methodologies (SCRUM) Strong problem solving and excellent communication skills, independent working style Experience in an FMCG company is a strong plus  RoleTechnical Architect Industry TypeAnalytics / KPO / Research Functional AreaIT Software - Application Programming, Maintenance Employment TypeFull Time, Permanent Role CategoryProgramming & Design Education UG :Any Graduate Key Skills Data ScienceRNLPNeural NetworksStatistical ModelingText MiningMachine LearningDeep LearningPythonRandom Forest',\n",
       " 'Job description Role: Data Scientist  Roles and Responsibilities Suitable candidates will be part of Wipro Digital-Intelligent Enterprise practice. The role entails leveraging Data Science and Machine Learning to solve typical problems within an organization and create IP that could be deployed in a productized mode. This will entail significant hands-on work on multiple Big Data Technologies, Data Analysis, Identifying data patterns, ML models, Insights generation. The role entails deployment in a customer context and managing customer expectations.  Technical Skills Required: Hands on with Python or R Analytics using industry leading BI tools and technologies Implementation knowledge of supervised\\\\un-supervised machine learning algorithms Good statistical analysis skills for data pre-processing and data wrangling Experienced in using big data frameworks like Hadoop Knowledge of business intelligence tools or reporting tools  Data Preparation for Modeling Missing Data Imputation,Outlier Treatment Scaling, Normalization, Standardization Encoding for Categorical Variables Oversampling\\\\Undersampling for reducing class imbalance  Experience in building solutions using Model Library Feature Selection Tree-based Ensemble Models Gradient\\\\Adaptive Boosted Trees Hyper-parameter tuning Building Prediction mechanisms using methods like Logistic regression, voting classifier stacking etc  RoleData Analyst Industry TypeIT Services & Consulting Functional AreaAnalytics & Business Intelligence Employment TypeFull Time, Permanent Role CategoryAnalytics & BI Education UG :B.Tech/BE in Any Specialization Key Skills Big DataMachine LearningPython Data ScienceRLogistic RegressionData WranglingHadoopData AnalysisStatistical Analysis Skills highlighted with ‘‘ are preferred keyskills',\n",
       " 'Job description Responsibilities: Build and Optimize Machine Learning models. Work with large/complex datasets to solve difficult and non-routine analysis problems, applying advanced analytical methods as needed. Build and prototype data pipelines for analysis at scale. Work cross-functionally with Business Analysts and Data Engineers to help develop cutting edge and innovative artificial intelligence and machine learning models. Make recommendations for selections on machine learning models. Drive accuracy levels to the next stage of the given ML models. Experience in developing visualization and User Good exposure in exploratory data analysis Strong experience in Statistics and ML algorithms. Minimum qualifications: (2-4) years of relevant work experience in ML and advanced data analytics(e.g., as a Machine Learning Specialist / Data scientist ). Strong Experience using machine learning and artificial intelligence frameworks such as Tensorflow, sci-kit learn, Keras using python. Good in Python/R/SAS programming. Understanding of Cloud platforms like GCP, AWS, or other. Preferred qualifications: Work experience in building data pipelines to ingest, cleanse and transform data. Applied experience with machine learning on large datasets and experience translating analysis results into business recommendations. Demonstrated skills in selecting the right statistical tools given a data analysis problem. Demonstrated effective written and verbal communication skills. Demonstrated willingness to both teach others and learn new techniques RoleSoftware Developer Industry TypeManagement Consulting Functional AreaIT Software - System Programming Employment TypeFull Time, Permanent Role CategoryProgramming & Design Education UG :B.Tech/BE in Any Specialization PG :Any Postgraduate Key Skills SANERPData analysisPrototypeMachine learningHealthcareApplication developmentciscoAnalyticsPython',\n",
       " 'Job description As our Senior Data Scientist, youll be an integral player in the Marketplace Data Science team based in Bengaluru. With the latest cutting-edge data science tech at your disposal, youll focus your efforts on bringing our Marketplace systems (i.e. supply, demand, and pricing) to the next level, employing various quantitative techniques such as Machine Learning, Optimization, Simulation, Bayesian Techniques to drive asymmetric values for our businesses at Gojek. Youll be heavily involved in ideation, research, and building prototypes, and the folks in the Data Science Platform will bring your models to production. Your efforts will directly influence the stability and scalability of Gojeks Marketplace stream, and thus to companys top and bottom line as a whole.   What You Will Do Work with Data Scientists, Machine Learning Engineers, and Business Users to build, deploy, and scale Data Science solutions on match-making, supply, pricing problems in Gojek that touch the company s baseline Use your experience in Data Science, Machine Learning, Software Engineering, distributed systems to develop these systems, and work with the platform team to take the systems to production Work with Business teams to continuously refine and improve the systems to cater to ever-changing Gojek needs Design and develop world class Data Science solutions to enhance the current stack of Marketplace algorithms for supply, demand, pricing What You Will Need At least 6 years of experience as a Data Scientist or Machine Learning Engineer, with experience in Python, Golang/Java, and Unix A Bachelors Degree in Computer Science, Statistics, Operations Research, or a relevant quantitative field Solid knowledge of Data Science and Machine Learning fundamentals, with proven experience formulating Data Science solutions to business problems Proven ability to recognize business needs and to communicate with multiple stakeholders within the Product Management, Business and Operations teams Experience in taking Data Science models to production Prior academic or industry work experience with forecasting methods like auto-regressive models, Markov models, and Kernel-based methods Prior experience with simulations for modeling the stochastic nature of marketplace supply and demand, and knowledge of the transportation and mobility space RoleTeam Lead/Technical Lead Industry TypeInternet Functional AreaIT Software - eCommerce, Internet Technologies Employment TypeFull Time, Permanent Role CategoryProgramming & Design Education UG :Any Graduate PG :Any Postgraduate Key Skills UnixProduct managementComputer scienceOperations researchSimulationMachine learningDistribution systemForecastingPythonLogistics',\n",
       " 'Job description As our Senior Data Scientist, youll be an integral player in the Marketplace Data Science team based in Bengaluru. With the latest cutting-edge data science tech at your disposal, youll focus your efforts on bringing our Marketplace systems (i.e. supply, demand, and pricing) to the next level, employing various quantitative techniques such as Machine Learning, Optimization, Simulation, Bayesian Techniques to drive asymmetric values for our businesses at Gojek. Youll be heavily involved in ideation, research, and building prototypes, and the folks in the Data Science Platform will bring your models to production. Your efforts will directly influence the stability and scalability of Gojeks Marketplace stream, and thus to companys top and bottom line as a whole.   What You Will Do Work with Data Scientists, Machine Learning Engineers, and Business Users to build, deploy, and scale Data Science solutions on match-making, supply, pricing problems in Gojek that touch the company s baseline Use your experience in Data Science, Machine Learning, Software Engineering, distributed systems to develop these systems, and work with the platform team to take the systems to production Work with Business teams to continuously refine and improve the systems to cater to ever-changing Gojek needs Design and develop world class Data Science solutions to enhance the current stack of Marketplace algorithms for supply, demand, pricing What You Will Need At least 6 years of experience as a Data Scientist or Machine Learning Engineer, with experience in Python, Golang/Java, and Unix A Bachelors Degree in Computer Science, Statistics, Operations Research, or a relevant quantitative field Solid knowledge of Data Science and Machine Learning fundamentals, with proven experience formulating Data Science solutions to business problems Proven ability to recognize business needs and to communicate with multiple stakeholders within the Product Management, Business and Operations teams Experience in taking Data Science models to production Prior academic or industry work experience with forecasting methods like auto-regressive models, Markov models, and Kernel-based methods Prior experience with simulations for modeling the stochastic nature of marketplace supply and demand, and knowledge of the transportation and mobility space RoleTeam Lead/Technical Lead Industry TypeIT Services & Consulting Functional AreaIT Software - eCommerce, Internet Technologies Employment TypeFull Time, Permanent Role CategoryProgramming & Design Education UG :Any Graduate PG :Any Postgraduate Key Skills UnixProduct managementComputer scienceOperations researchSimulationMachine learningDistribution systemForecastingPythonLogistics',\n",
       " 'Job description Epsilon India team is looking for a talented team player in a Senior Data Scientist. You are an expert, mentor and advocate. You have strong machine learning and deep learning background and are passionate about transforming data into ml models. You welcome the challenge of data science and are proficient in Python, Spark MLLib, Tensorflow, Keras, ML algortihms and Deep Neural Networks, Big Data. You must be self-driven, take initiative and want to work in a dynamic, busy and innovative group. You will work with a distributed team (onshore and offshore) and work closely with a broadly talented team of delivery management, business analysts, visual designers, analytics, developers, and QA. You will work directly with clients to own data science solutions as a member of the Data Sciences MML Cloud Services team, and will operate as part of the product team to extend the Platform functionality when not supporting client projects Perform hands-on analysis of large volumes of web analytics, transaction, customer data, second and third-party data. Work with complex data structure, manipulate, cleanse data and perform statistical analysis Design and Implement Machine learning models using Spark ML, Python, Map-Reduce, Hive, HDFS, Spring, Hibernate and Java Design and implement Deep neural network models using Tensorflow, Pytorch, Keras and Python Create engaging and meaningful data visualizations of findings linked to clear client business impact. Develop machine learning pipelines with big data design principles in MS Azure cloud using Azure Data Factory Own end to end implementations of Marketing machine learning models such as Churn, CLV, Propensity, Affinity models.   Qualifications Experience with large scale distributed databases and computing systems like Hadoop, HDInsight or DataBricks Strong passion for understanding key business problems, bringing together a team to understand data/ instrumentation needs and/or mine through data to unearth deep insights into customer experiences Proven capability to deliver end-to-end analyses by asking the right questions, extracting data, and building predictive models to ensure actionable results. Excellent communication interpersonal skills with an ability to communicate ideas. MS or Ph.D. in Computer Science, Math, Physics, or equivalent education/professional experience is required. 6+ years of overall IT experience with 2+ years in a data science role with demonstrable experience Deep experience in machine learning with Spark and Azure Machine Learning and Cognitive Services. Azure Cloud experience required. Azure Data Factory experience preferred. Strong experience in DNN models using Tensorflow v1.8 above, Keras, Pytorch Experience with sequence modeling using RNNs/LSTMs is good to have Strong experience in at least one database technology (i.e. Hive, PrestoDb etc.) Strong experience in at least one programming language (i.e. Python, R, C, C++ is plus) Experience working with different query languages (i.e. PL-SQL, T-SQL) Understanding and experience working with cloud infrastructure services like Azure and Amazon Web Services. Azure preferred. Experience working with code repositories and continuous integration (i.e. Git, Jenkins, etc.) Strong passion for understanding key business problems, bringing together the team to understand data/ instrumentation needs and/or mine through data to unearth deep insights into customer experiences   RoleOutside Consultant Industry TypeAdvertising & Marketing Functional AreaIT Software - Application Programming, Maintenance Employment TypeFull Time, Permanent Role CategoryOther Education UG :Any Graduate PG :Any Postgraduate Key Skills Computer scienceHibernateGITWeb analyticsPAASMachine learningPLSQLInstrumentationinfrastructure servicesPython',\n",
       " 'Job description The Challenge Be a thought leader, partner with your cross-functional partners to foster a data driven payments organization. With a focus on Payments compliance and keeping our platform safe, anticipate and detect new fraud trends and regulatory requirements. Define and evaluate key metrics. Build the data foundation you need, in partnership with the data engineering team. Deliver actionable user-insights to build the best products and models Design experiments to measure the impact of new payments features Empower the product and engineering teams to make data-driven decisions What you need to succeed 4+ years industry experience in a quantitative analysis role. Experience in Payments a strong plus Fluent in SQL and proficiency in analytical tools such as Python, R, etc. Background in statistics and experience with experimentation Solid understanding of product analytics Experience or willingness to learn tools to create data pipelines using Airflow/Minerva Ability to communicate clearly and effectively to cross functional partners of varying technical levels RoleSoftware Developer Industry TypeInternet Functional AreaIT Software - Application Programming, Maintenance Employment TypeFull Time, Permanent Role CategoryProgramming & Design Education UG :B.Sc/B.Sc(Hons) in Statistics, Any Graduate Key Skills AirflowQuantitative AnalysisMinervaRData EngineeringXMLBuildProduct AnalyticsStatisticsAnalyticsSQLPython',\n",
       " 'Job description Building Machine learning models for credit underwriting Exploring different machine learning modelling techniques to build the optimum solution. Machine learning model parameter tuning. Ad hoc Credit analysis. Create a highly modular code data extraction layer, data transformation layer, modeling layer, results streaming layer Automation of repetitive codes, strong bug fixing skill. Manage code repository as well Critical: Building credit scoring model for MSME lending Immediate joinee Skills Strong python skills to develop Credit score models Strong Understanding of modelling techniques- XGBoost, Random forest, logistic regression, IV, WOE etc. Understanding of Credit Bureau features Good at SQL Good knowledge in excel Education Btech. RoleInstructional Designer Industry TypeFinancial Services Functional AreaIT Software - Application Programming, Maintenance Employment TypeFull Time, Permanent Role CategoryQA/Testing/Documentation Education UG :B.Tech/BE in Production/Industrial PG :Post Graduation Not Required Key Skills Logistic regressionAutomationExcelMachine learningCredit underwritingCredit analysisManagementSQLData extractionPython']"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fulljobdesc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>Job description</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>24/7 Customer</td>\n",
       "      <td>Job description Brief about the Role The Platf...</td>\n",
       "      <td>Not Disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>3.6(1198 Reviews)</td>\n",
       "      <td>Job description The Artificial Intelligence an...</td>\n",
       "      <td>Not Disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>Job description ABOUT THIS JOB NielsenIQ Advan...</td>\n",
       "      <td>Not Disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>3.9(97 Reviews)</td>\n",
       "      <td>Job description Role: Data Scientist  Roles an...</td>\n",
       "      <td>Not Disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td></td>\n",
       "      <td>Job description Responsibilities: Build and Op...</td>\n",
       "      <td>Not Disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td></td>\n",
       "      <td>Job description As our Senior Data Scientist, ...</td>\n",
       "      <td>Not Disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Nielsen</td>\n",
       "      <td>Job description As our Senior Data Scientist, ...</td>\n",
       "      <td>Not Disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>3.8(483 Reviews)</td>\n",
       "      <td>Job description Epsilon India team is looking ...</td>\n",
       "      <td>Not Disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sr Data Scientist, Payments</td>\n",
       "      <td></td>\n",
       "      <td>Job description The Challenge Be a thought lea...</td>\n",
       "      <td>Not Disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td></td>\n",
       "      <td>Job description Building Machine learning mode...</td>\n",
       "      <td>Not Disclosed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         title            company  \\\n",
       "0        Senior Data Scientist      24/7 Customer   \n",
       "1        Senior Data Scientist  3.6(1198 Reviews)   \n",
       "2        Senior Data Scientist  Fractal Analytics   \n",
       "3               Data Scientist    3.9(97 Reviews)   \n",
       "4        Senior Data Scientist                      \n",
       "5        Senior Data Scientist                      \n",
       "6        Senior Data Scientist            Nielsen   \n",
       "7        Senior Data Scientist   3.8(483 Reviews)   \n",
       "8  Sr Data Scientist, Payments                      \n",
       "9        Senior Data Scientist                      \n",
       "\n",
       "                                     Job description         salary  \n",
       "0  Job description Brief about the Role The Platf...  Not Disclosed  \n",
       "1  Job description The Artificial Intelligence an...  Not Disclosed  \n",
       "2  Job description ABOUT THIS JOB NielsenIQ Advan...  Not Disclosed  \n",
       "3  Job description Role: Data Scientist  Roles an...  Not Disclosed  \n",
       "4  Job description Responsibilities: Build and Op...  Not Disclosed  \n",
       "5  Job description As our Senior Data Scientist, ...  Not Disclosed  \n",
       "6  Job description As our Senior Data Scientist, ...  Not Disclosed  \n",
       "7  Job description Epsilon India team is looking ...  Not Disclosed  \n",
       "8  Job description The Challenge Be a thought lea...  Not Disclosed  \n",
       "9  Job description Building Machine learning mode...  Not Disclosed  "
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "jobs=pd.DataFrame({})\n",
    "jobs['title']=jobtitles[:10]   \n",
    "jobs['company']=companyName[:10]  \n",
    "jobs['Job description']=fulljobdesc[:10]   \n",
    "jobs['salary']=salarytitles[:10] \n",
    "\n",
    "\n",
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first get the webpage https://www.naukri.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\chromedriver.exe\")\n",
    "url='https://www.naukri.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter “Data Scientist” in “Skill,Designations,Companies” field ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_job=driver.find_element_by_xpath('//input[@class=\"sugInp\"]')\n",
    "search_job.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "click the search button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn=driver.find_element_by_xpath(\"//button[@class='btn']\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "apply the location filter-“Delhi/NCR”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn1=driver.find_element_by_xpath(\"//span[@title='Delhi / NCR']\")\n",
    "search_btn1.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "apply the salary filter to be used: “3-6” lakhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn2=driver.find_element_by_xpath(\"/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[3]/div[2]/div[2]/label/p/span[1]\")\n",
    "search_btn2.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Then scrape the data for the first 10 jobs results you get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "#job title\n",
    "alltitle=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "\n",
    "job_titles=[]\n",
    "for i in alltitle:\n",
    "    job_titles.append(i.text)\n",
    "\n",
    "\n",
    "#company\n",
    "companies_tags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "\n",
    "companies_tags_titles=[]\n",
    "for i in companies_tags:\n",
    "    companies_tags_titles.append(i.text)\n",
    "\n",
    "\n",
    "#experience\n",
    "experience_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']//span\")\n",
    "\n",
    "experience_tags_titles=[]\n",
    "for i in experience_tags:\n",
    "    experience_tags_titles.append(i.text)\n",
    "\n",
    "\n",
    "#Location\n",
    "location_title=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']//span\")\n",
    "\n",
    "location_tags_titles=[]\n",
    "for i in location_title:\n",
    "    location_tags_titles.append(i.text)\n",
    "    \n",
    "\n",
    "\n",
    "#salary\n",
    "salary_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi salary']//span\")\n",
    "\n",
    "\n",
    "salary_tags_titles=[]\n",
    "for i in salary_tags:\n",
    "    salary_tags_titles.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>experience</th>\n",
       "      <th>salary</th>\n",
       "      <th>place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist - Machine Learning/ NLP</td>\n",
       "      <td>TalPro</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Only Fresher / Data Scientist / Data Analyst /...</td>\n",
       "      <td>GABA Consultancy services</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "      <td>2,25,000 - 4,75,000 PA.</td>\n",
       "      <td>Noida, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>3,50,000 - 4,50,000 PA.</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist -Delhi</td>\n",
       "      <td>CHANGE LEADERS CONSULTING</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>New Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist - Text NLP | Noida</td>\n",
       "      <td>Acidaes Solutions Pvt. Ltd.</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>NEC CORPORATION INDIA PRIVATE LIMITED</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist - Machine Learning/NLP</td>\n",
       "      <td>TalPro</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist - Machine Learning/NLP</td>\n",
       "      <td>TalPro</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data analytics / Data scientist intern (work f...</td>\n",
       "      <td>TalkValley LLC</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "      <td>2,00,000 - 3,00,000 PA.</td>\n",
       "      <td>Kolkata, Bangalore/Bengaluru, Delhi / NCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chaayos is Looking For Data Scientist</td>\n",
       "      <td>Chaayos (Sunshine Teahouse Pvt. Ltd.)</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>New Delhi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0             Data Scientist - Machine Learning/ NLP   \n",
       "1  Only Fresher / Data Scientist / Data Analyst /...   \n",
       "2    Data Scientist / Data Analyst -Business Analyst   \n",
       "3                              Data Scientist -Delhi   \n",
       "4                  Data Scientist - Text NLP | Noida   \n",
       "5                                     Data Scientist   \n",
       "6              Data Scientist - Machine Learning/NLP   \n",
       "7              Data Scientist - Machine Learning/NLP   \n",
       "8  Data analytics / Data scientist intern (work f...   \n",
       "9              Chaayos is Looking For Data Scientist   \n",
       "\n",
       "                                 company experience                   salary  \\\n",
       "0                                 TalPro    2-6 Yrs            Not disclosed   \n",
       "1              GABA Consultancy services    0-0 Yrs  2,25,000 - 4,75,000 PA.   \n",
       "2     Inflexion Analytix Private Limited    0-3 Yrs  3,50,000 - 4,50,000 PA.   \n",
       "3              CHANGE LEADERS CONSULTING    5-8 Yrs            Not disclosed   \n",
       "4            Acidaes Solutions Pvt. Ltd.    3-5 Yrs            Not disclosed   \n",
       "5  NEC CORPORATION INDIA PRIVATE LIMITED    3-8 Yrs            Not disclosed   \n",
       "6                                 TalPro    2-6 Yrs            Not disclosed   \n",
       "7                                 TalPro    2-4 Yrs            Not disclosed   \n",
       "8                         TalkValley LLC    0-5 Yrs  2,00,000 - 3,00,000 PA.   \n",
       "9  Chaayos (Sunshine Teahouse Pvt. Ltd.)    0-5 Yrs            Not disclosed   \n",
       "\n",
       "                                               place  \n",
       "0                                   Gurgaon/Gurugram  \n",
       "1               Noida, Gurgaon/Gurugram, Delhi / NCR  \n",
       "2  Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...  \n",
       "3                                          New Delhi  \n",
       "4                                              Noida  \n",
       "5                                              Noida  \n",
       "6                                   Gurgaon/Gurugram  \n",
       "7                                   Gurgaon/Gurugram  \n",
       "8          Kolkata, Bangalore/Bengaluru, Delhi / NCR  \n",
       "9                                          New Delhi  "
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "jobs=pd.DataFrame({})\n",
    "jobs['title']=job_titles[:10]\n",
    "jobs['company']=companies_tags_titles[:10]\n",
    "jobs['experience']=experience_tags_titles[:10]\n",
    "jobs['salary']=salary_tags_titles[:10]\n",
    "jobs['place']=location_tags_titles[:10]\n",
    "\n",
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get the webpage https://www.glassdoor.co.in/index.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\chromedriver.exe\")\n",
    "url='https://www.glassdoor.co.in/index.htm'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sign in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.implicitly_wait(10)\n",
    "sign_in_btn=driver.find_element_by_xpath(\"//div[@class='d-flex justify-content-center order-1 order-md-2 LockedHomeHeaderStyles__flexibleContainer']//button\")\n",
    "sign_in_btn.click()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "username:aneeshabsoman123@gmail.com\n",
    "\n",
    "password:fliprobo2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "username=driver.find_element_by_xpath('//input[@id=\"userEmail\"]')\n",
    "username.send_keys(\"aneeshabsoman123@gmail.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "password=driver.find_element_by_xpath('//input[@id=\"userPassword\"]')\n",
    "password.send_keys(\"fliprobo2021\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_in_btn=driver.find_element_by_xpath(\"//button[@class='gd-ui-button minWidthBtn css-8i7bc2']\")\n",
    "sign_in_btn.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Enter “Data Scientist” in “Job Title,Keyword,Company” field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_job=driver.find_element_by_xpath('//div[@class=\"col headerSearchInput css-1ohf0ui\"]//div//input')\n",
    "search_job.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "enter “Noida” in “location” field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "search_place=driver.find_element_by_xpath('/html/body/header/nav[1]/div/div/div/div[4]/div[2]/form/div/div[3]/div/input')\n",
    "search_place.clear()\n",
    "search_place.send_keys(\"Noida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " click the search button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "search_btn=driver.find_element_by_xpath(\"/html/body/header/nav[1]/div/div/div/div[4]/div[2]/form/div/button\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "#job title\n",
    "alltitle=driver.find_elements_by_xpath(\"//a[@class='jobLink css-1rd3saf eigr9kq2']\")\n",
    "\n",
    "job_titles=[]\n",
    "for i in alltitle:\n",
    "    job_titles.append(i.text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist',\n",
       " 'Data Science Trainee',\n",
       " 'Data Analyst / Data Scientist',\n",
       " 'Data Scientist',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#company\n",
    "companies_tags=driver.find_elements_by_xpath(\"//a[@class=' css-l2wjgv e1n63ojh0 jobLink']//span\")\n",
    "\n",
    "companies_tags_titles=[]\n",
    "for i in companies_tags:\n",
    "    companies_tags_titles.append(i.text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Patterns',\n",
       " 'Algo8 AI Pvt. Ltd.',\n",
       " 'Ginger Webs Pvt. Ltd.',\n",
       " 'Siemens Technology and Services Private Limited',\n",
       " 'Ericsson',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companies_tags_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Location\n",
    "location_title=driver.find_elements_by_xpath(\"//span[@class='pr-xxsm css-1ndif2q e1rrn5ka0']\")\n",
    "\n",
    "location_tags_titles=[]\n",
    "for i in location_title:\n",
    "    location_tags_titles.append(i.text)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#salary\n",
    "salary_tags=driver.find_elements_by_xpath(\"//span[@class='css-1imh2hq e1wijj242']\")\n",
    "\n",
    "\n",
    "salary_tags_titles=[]\n",
    "for i in salary_tags:\n",
    "    salary_tags_titles.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (1) does not match length of index (10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-230-3b98a9a5c889>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mjobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mjobs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'title'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjob_titles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mjobs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'company'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompanies_tags_titles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mjobs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'salary'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msalary_tags_titles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mjobs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'place'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlocation_tags_titles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3038\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3039\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3040\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3114\u001b[0m         \"\"\"\n\u001b[0;32m   3115\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3116\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3117\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[1;34m(self, key, value, broadcast)\u001b[0m\n\u001b[0;32m   3762\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3763\u001b[0m             \u001b[1;31m# turn me into an ndarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3764\u001b[1;33m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msanitize_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3765\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3766\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36msanitize_index\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    745\u001b[0m     \"\"\"\n\u001b[0;32m    746\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 747\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    748\u001b[0m             \u001b[1;34m\"Length of values \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    749\u001b[0m             \u001b[1;34mf\"({len(data)}) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (1) does not match length of index (10)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "jobs=pd.DataFrame({})\n",
    "jobs['title']=job_titles[:10]\n",
    "jobs['company']=companies_tags_titles[:10]\n",
    "jobs['salary']=salary_tags_titles[:10]\n",
    "jobs['place']=location_tags_titles[:10]\n",
    "\n",
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first get the webpage https://www.glassdoor.co.in/Salaries/index.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\chromedriver.exe\")\n",
    "url='https://www.glassdoor.co.in/Salaries/index.htm'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ElementNotInteractableException",
     "evalue": "Message: element not interactable\n  (Session info: chrome=91.0.4472.114)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mElementNotInteractableException\u001b[0m           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-cb8030e905b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimplicitly_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msign_in_btn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"//div[@class='d-flex justify-content-center order-1 order-md-2 LockedHomeHeaderStyles__flexibleContainer']//button\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msign_in_btn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36mclick\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;34m\"\"\"Clicks the element.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_execute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCLICK_ELEMENT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msubmit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36m_execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    631\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 633\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    634\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mElementNotInteractableException\u001b[0m: Message: element not interactable\n  (Session info: chrome=91.0.4472.114)\n"
     ]
    }
   ],
   "source": [
    "driver.implicitly_wait(10)\n",
    "sign_in_btn=driver.find_element_by_xpath(\"//div[@class='d-flex justify-content-center order-1 order-md-2 LockedHomeHeaderStyles__flexibleContainer']//button\")\n",
    "sign_in_btn.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username=driver.find_element_by_xpath('//input[@id=\"userEmail\"]')\n",
    "username.send_keys(\"aneeshabsoman123@gmail.com\")\n",
    "\n",
    "driver.implicitly_wait(5)\n",
    "\n",
    "password=driver.find_element_by_xpath('//input[@id=\"userPassword\"]')\n",
    "password.send_keys(\"fliprobo2021\")\n",
    "\n",
    "driver.implicitly_wait(5)\n",
    "\n",
    "sign_in_btn=driver.find_element_by_xpath(\"//button[@class='gd-ui-button minWidthBtn css-8i7bc2']\")\n",
    "sign_in_btn.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter “Data Scientist” in Job title field and “Noida” in location field.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_job=driver.find_element_by_xpath('//input[@id=\"KeywordSearch\"]')\n",
    "search_place.clear()\n",
    "search_job.send_keys(\"Data Scientist\")\n",
    "\n",
    "search_place=driver.find_element_by_xpath('//input[@id=\"LocationSearch\"]')\n",
    "search_place.clear()\n",
    "search_place.send_keys(\"Noida\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "click the search button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn=driver.find_element_by_xpath('//button[@id=\"HeroSearchButton\"]')\n",
    "search_btn.click()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Company name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "WebDriverException",
     "evalue": "Message: chrome not reachable\n  (Session info: chrome=91.0.4472.114)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-e396a634501e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#company\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcompanies_tags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_elements_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"//a[@class='css-f3vw95 e1aj7ssy3 ']\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcompanies_tags_titles\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcompanies_tags\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_elements_by_xpath\u001b[1;34m(self, xpath)\u001b[0m\n\u001b[0;32m    408\u001b[0m             \u001b[0melements\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_elements_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"//div[contains(@class, 'foo')]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m         \"\"\"\n\u001b[1;32m--> 410\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_elements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_element_by_link_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlink_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_elements\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m   1003\u001b[0m         \u001b[1;31m# Return empty list if driver returns null\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1004\u001b[0m         \u001b[1;31m# See https://github.com/SeleniumHQ/selenium/issues/4555\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1005\u001b[1;33m         return self.execute(Command.FIND_ELEMENTS, {\n\u001b[0m\u001b[0;32m   1006\u001b[0m             \u001b[1;34m'using'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1007\u001b[0m             'value': value})['value'] or []\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mWebDriverException\u001b[0m: Message: chrome not reachable\n  (Session info: chrome=91.0.4472.114)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#company\n",
    "companies_tags=driver.find_elements_by_xpath(\"//a[@class='css-f3vw95 e1aj7ssy3']\")\n",
    "\n",
    "companies_tags_titles=[]\n",
    "for i in companies_tags:\n",
    "    companies_tags_titles.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies_tags_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "WebDriverException",
     "evalue": "Message: chrome not reachable\n  (Session info: chrome=91.0.4472.114)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-6407fdb3599e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#company\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcompanies_tags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_elements_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"//div[@class='col-12 col-lg-auto']//span \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcompanies_tags_titles\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcompanies_tags\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_elements_by_xpath\u001b[1;34m(self, xpath)\u001b[0m\n\u001b[0;32m    408\u001b[0m             \u001b[0melements\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_elements_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"//div[contains(@class, 'foo')]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m         \"\"\"\n\u001b[1;32m--> 410\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_elements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_element_by_link_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlink_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_elements\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m   1003\u001b[0m         \u001b[1;31m# Return empty list if driver returns null\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1004\u001b[0m         \u001b[1;31m# See https://github.com/SeleniumHQ/selenium/issues/4555\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1005\u001b[1;33m         return self.execute(Command.FIND_ELEMENTS, {\n\u001b[0m\u001b[0;32m   1006\u001b[0m             \u001b[1;34m'using'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1007\u001b[0m             'value': value})['value'] or []\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mWebDriverException\u001b[0m: Message: chrome not reachable\n  (Session info: chrome=91.0.4472.114)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Numberofsalaries_tags=driver.find_elements_by_xpath(\"//div[@class='col-12 col-lg-auto']//span \")\n",
    "\n",
    "Numberofsalaries_tags_titles=[]\n",
    "for i in Numberofsalaries_tags:\n",
    "    Numberofsalaries_tags_titles.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Numberofsalaries_tags_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average salary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Averagesalary_tags=driver.find_elements_by_xpath(\"//div[@class='col-12 col-lg-4 px-lg-0 d-flex align-items-baseline']//h3 \")\n",
    "\n",
    "Averagesalary_tags_titles=[]\n",
    "for i in Averagesalary_tags:\n",
    "    Averagesalary_tags_titles.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Averagesalary_tags_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimum salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Minimumsalary_tags=driver.find_elements_by_xpath(\"//div[@class='d-flex mt-xxsm css-79elbk epuxyqn0']//p \")\n",
    "\n",
    "Minimumsalary_tags_titles=[]\n",
    "for i in Minimumsalary_tags:\n",
    "    Minimumsalary_tags_titles.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Minimumsalary_tags_titles_new=[]\n",
    "for i in range(1,len(Minimumsalary_tags_titles),2):\n",
    "    Minimumsalary_tags_titles_new.append(Minimumsalary_tags_titles[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Minimumsalary_tags_titles_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maximum Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Maximumsalary_tags=driver.find_elements_by_xpath(\"//div[@class='d-flex mt-xxsm css-79elbk epuxyqn0']//p \")\n",
    "\n",
    "Maximumsalary_tags_titles=[]\n",
    "for i in Maximumsalary_tags:\n",
    "    Maximumsalary_tags_titles.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Maximumsalary_tags_titles_new=[]\n",
    "for i in range(1,len(Maximumsalary_tags_titles),2):\n",
    "    Maximumsalary_tags_titles_new.append(Maximumsalary_tags_titles[i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Maximumsalary_tags_titles_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'companies_tags_titles' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-d0d33fb672cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mjobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mjobs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'company'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompanies_tags_titles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mjobs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Number of salaries'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNumberofsalaries_tags_titles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mjobs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Average salary'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mAveragesalary_tags_titles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'companies_tags_titles' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "jobs=pd.DataFrame({})\n",
    "\n",
    "jobs['company']=companies_tags_titles[:10]\n",
    "jobs['Number of salaries']=Numberofsalaries_tags_titles[:10][:10]\n",
    "jobs['Average salary']=Averagesalary_tags_titles[:10]\n",
    "jobs['Minimum salary']=Minimumsalary_tags_titles_new[:10][:10]\n",
    "jobs['Maximum Salary']=Maximumsalary_tags_titles_new[:10]\n",
    "\n",
    "\n",
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to flipkart webpage by url https://www.flipkart.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\chromedriver.exe\")\n",
    "url=' https://www.flipkart.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter “sunglasses” in the search field "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "productinput=driver.find_element_by_xpath('/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input')\n",
    "productinput.send_keys(\"sunglasses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " click the search icon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn=driver.find_element_by_xpath('/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button')\n",
    "search_btn.click()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Brand\n",
    "\n",
    "2. Product Description\n",
    "\n",
    "3. Price\n",
    "\n",
    "4. Discount %\n",
    "\n",
    "from 3 pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,3):\n",
    "    \n",
    "    #brand name\n",
    "    Brand_tags=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "\n",
    "    Brand_tags_titles=[]\n",
    "    for j in Brand_tags:\n",
    "        Brand_tags_titles.append(i.text)\n",
    "        \n",
    "    #Product description    \n",
    "    ProductDescription_tags=driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "\n",
    "    ProductDescription_tags_titles=[]\n",
    "    for k in ProductDescription_tags:\n",
    "        ProductDescription_tags_titles.append(i.text)\n",
    "        \n",
    "    #price tag\n",
    "    Price_tags=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "\n",
    "    Price_tags_titles=[]\n",
    "    for l in Price_tags:\n",
    "        Price_tags_titles.append(i.text)\n",
    "        \n",
    "    #discount\n",
    "    Discount_tags=driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']//span\")\n",
    "\n",
    "    Discount_tags_titles=[]\n",
    "    for m in Discount_tags:\n",
    "        Discount_tags_titles.append(i.text)\n",
    "        \n",
    "    next_button=driver.find_element_by_xpath(\"/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]/span']\")\n",
    "    next_button.click()\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "product=pd.DataFrame({})\n",
    "\n",
    "product['Product name']=Brand_tags_titles[:100]\n",
    "product['Product description']=ProductDescription_tags_titless[:100]\n",
    "product['price tag']=Price_tags_titles[:100]\n",
    "product['discount']=Discount_tags_titles[:100]\n",
    "\n",
    "\n",
    "\n",
    "product\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Rating\n",
    "\n",
    "2. Review_summary\n",
    "\n",
    "3. Full review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\chromedriver.exe\")\n",
    "url=' https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "allreview=driver.find_element_by_xpath(\"/html/body/div[1]/div/div[3]/div[1]/div[2]/div[8]/div/div/div[5]/div/a/div/span\")\n",
    "allreview.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,10):\n",
    "    \n",
    "    #rating\n",
    "    rating_tags=driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\")\n",
    "\n",
    "    rating_tags_titles=[]\n",
    "    for j in rating_tags:\n",
    "        rating_tags_titles.append(i.text)\n",
    "        \n",
    "    #Review_summary    \n",
    "    Review_summary=driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\")\n",
    "\n",
    "    Review_summary_tags_titles=[]\n",
    "    for k in Review_summary:\n",
    "        Review_summary_tags_titles.append(i.text)\n",
    "        \n",
    "    #Full review\n",
    "    Full_review=driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']\")\n",
    "\n",
    "    Full_review_tags_titles=[]\n",
    "    for l in Full_review:\n",
    "        Full_review_tags_titles.append(i.text)\n",
    "    \n",
    "    nextpage=driver.find_element_by_xpath(\"//a[@class='_1LKTO3']//span\")\n",
    "    nextpage.click()\n",
    "    time.sleep(2)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "review=pd.DataFrame({})\n",
    "\n",
    "review['rating']=rating_tags_titles[:100]\n",
    "review['Review_summary']=Review_summary_tags_titles[:100]\n",
    "review['Full review']=Full_review_tags_titles[:100]\n",
    "\n",
    "review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape data for first 100 sneakers you find when you visit flipkart.com and\n",
    "search for “sneakers” in the search field.\n",
    "You have to scrape 4 attributes of each sneaker :\n",
    "\n",
    "1. Brand\n",
    "\n",
    "2. Product Description\n",
    "\n",
    "3. Price\n",
    "\n",
    "4. discount %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\chromedriver.exe\")\n",
    "url='https://www.flipkart.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "productinput=driver.find_element_by_xpath('/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input')\n",
    "productinput.send_keys(\"sneakers\")\n",
    "driver.implicitly_wait(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn=driver.find_element_by_xpath('/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button')\n",
    "search_btn.click()\n",
    "driver.implicitly_wait(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,4):\n",
    "    \n",
    "    #brand name\n",
    "    Brand_tags=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "\n",
    "    Brand_tags_titles=[]\n",
    "    for j in Brand_tags:\n",
    "        Brand_tags_titles.append(i.text)\n",
    "        \n",
    "    #Product description    \n",
    "    ProductDescription_tags=driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "\n",
    "    ProductDescription_tags_titles=[]\n",
    "    for k in ProductDescription_tags:\n",
    "        ProductDescription_tags_titles.append(i.text)\n",
    "        \n",
    "    #price tag and discount\n",
    "    Price_tags=driver.find_elements_by_xpath(\"//a[@class='_25b18c']//div//div\")\n",
    "\n",
    "    Price_tags_titles=[]\n",
    "    Discount_tags_titles=[]\n",
    "    for l in Price_tags:\n",
    "        Price_tags_titles.append(i.text)\n",
    "        \n",
    "        Price_tags_titles_newlist=[]\n",
    "        for n in range(1,len(Price_tags_titles),3):\n",
    "            Price_tags_titles_newlist.append(Price_tags_titles[n])  \n",
    "            Discount_tags_titles.append(Price_tags_titles[n+2]) \n",
    "\n",
    "        \n",
    "    next_button=driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "    next_button.click()\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "product=pd.DataFrame({})\n",
    "\n",
    "product['Product name']=Brand_tags_titles[:100]\n",
    "product['Product description']=ProductDescription_tags_titless[:100]\n",
    "product['price tag']=Price_tags_titles[:100]\n",
    "product['discount']=Discount_tags_titles[:100]\n",
    "\n",
    "product\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Go to the link - https://www.myntra.com/shoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\chromedriver.exe\")\n",
    "url='https://www.myntra.com/shoes'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "btn1=driver.find_element_by_xpath(\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[3]/label\")\n",
    "btn1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "btn2=driver.find_element_by_xpath(\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label\")\n",
    "btn2.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,2):\n",
    "    \n",
    "    #brand name\n",
    "    Brand_tags=driver.find_elements_by_xpath(\"//h3[@class='product-brand']\")\n",
    "\n",
    "    Brand_tags_titles=[]\n",
    "    for j in Brand_tags:\n",
    "        Brand_tags_titles.append(i.text)\n",
    "        \n",
    "    #Product description    \n",
    "    ProductDescription_tags=driver.find_elements_by_xpath(\"//h4[@class='product-product']\")\n",
    "\n",
    "    ProductDescription_tags_titles=[]\n",
    "    for k in ProductDescription_tags:\n",
    "        ProductDescription_tags_titles.append(i.text)\n",
    "        \n",
    "    #price tag \n",
    "    Price_tags=driver.find_elements_by_xpath(\"//div[@class='product-price']\")\n",
    "\n",
    "    Price_tags_titles=[]\n",
    "  \n",
    "    for l in Price_tags:\n",
    "        Price_tags_titles.append(i.text)\n",
    "        \n",
    "    next_button=driver.find_element_by_xpath(\"//li[@class='pagination-next']\")\n",
    "    next_button.click()\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "product=pd.DataFrame({})\n",
    "\n",
    "product['Product name']=Brand_tags_titles[:100]\n",
    "product['Product description']=ProductDescription_tags_titless[:100]\n",
    "product['price tag']=Price_tags_titles[:100]\n",
    "\n",
    "product\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Go to webpage https://www.amazon.in/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\chromedriver.exe\")\n",
    "url='https://www.amazon.in/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter “Laptop” in the search field and then click the search icon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_bar=driver.find_element_by_id('twotabsearchtextbox')\n",
    "search_bar.send_keys(\"Laptop\")\n",
    "\n",
    "driver.implicitly_wait(5)\n",
    "\n",
    "search_btn=driver.find_element_by_xpath(\"//div[@class='nav-search-submit nav-sprite']/span/input\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " set CPU Type filter to “Intel Core i7” and “Intel Core i9” "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "btn1=driver.find_element_by_xpath(\"/html/body/div[1]/div[2]/div[1]/div/div[2]/div/div[3]/span/div[1]/span/div/div/div[6]/ul[1]/li[26]/span/a/span\")\n",
    "btn1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "btn2=driver.find_element_by_xpath(\"/html/body/div[1]/div[2]/div[1]/div/div[2]/div/div[3]/span/div[1]/span/div/div/div[6]/ul[1]/li[28]/span/a/span\")\n",
    "btn2.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scrape first 10 laptops data. You have to scrape 3 attributes\n",
    "for each laptop:\n",
    "1. title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HP Pavilion (2021) Thin & Light 11th Gen Core i7 Laptop, 16 GB RAM, 1TB SSD, Iris Xe Graphics, 14\" (35.56cms) FHD Screen, Windows 10, MS Office, Backlit Keyboard (14-dv0058TU)',\n",
       " 'ASUS ROG Zephyrus M15 (2020), 15.6\" 4K UHD, Intel Core i7-10750H 10th Gen, RTX 2060 GDDR6 6GB Graphics, Gaming Laptop (16GB RAM/1TB NVMe SSD/Windows 10/Prism Black/1.9 Kg), GU502LV-HC140T',\n",
       " 'HP Pavilion Gaming 10th Gen Intel Core i7 Processor 15.6-inch FHD Gaming Laptop (16GB/512GB SSD + 32GB Intel Optane/Windows 10/NVIDIA 1650Ti 4GB/Shadow Black), 15-dk1509TX',\n",
       " '(Renewed) Dell Intel Core i7 4th Gen 14 Inch(35.56cms)1366x768 HD Laptop (16GB RAM/128GB SSD & 2TB HDD/Windows 10 Pro/MS Office/Intel Integrated HD Graphics 4600/2.1Kg,Silver) Latitude E6440',\n",
       " 'Lenovo Yoga 7 11th Gen Intel Core i7 14\" (35.56cms) Full HD IPS 2-in-1 Touchscreen Laptop (16GB/512GB SSD/Windows 10/MS Office 2019/Fingerprint Reader/Slate Grey/Aluminium Surface/1.43Kg), 82BH004HIN',\n",
       " 'ASUS TUF Gaming F15, 15.6\" FHD 144Hz, Intel Core i7-10870H 10th Gen, GTX 1650 Ti GDDR6 4GB Graphics, Gaming Laptop (16GB RAM/1TB HDD + 256GB SSD/Windows 10/Fortress Gray/2.3 Kg), FX566LI-HN133T',\n",
       " 'HP Pavilion x360 (2021) 14\" (35.56cms) FHD Touchscreen Laptop, 11th Gen Core i7, 8 GB RAM, 512GB SSD, 2-in-1 Convertible, Windows 10, MS Office, Finger Print Reader (14-dw1040TU)',\n",
       " 'Mi Notebook Horizon Edition 14 Intel Core i5-10210U 10th Gen 14-inch (35.56 cms) Thin and Light Laptop(8GB/512GB SSD/Windows 10/Nvidia MX350 2GB Graphics/Grey/1.35Kg), XMA1904-AR+Webcam',\n",
       " 'ASUS ROG Zephyrus Duo 15, 15.6\" 4K UHD, Intel Core i7-10875H 10th Gen, RTX 2080 Super Max-Q 8GB Graphics, Gaming Laptop (32GB/2TB RAID 0 SSD/Windows 10/MS Office/Gray/2.48 Kg) GX550LXS-HC145TS',\n",
       " 'ASUS VivoBook S S14 Intel Core i7-1165G7 11th Gen, 14-inch FHD Thin and Light Laptop (8GB RAM/512GB SSD + 32GB Optane Memory/Windows 10/Office 2019/Iris X Graphics- Indie Black/1.4 Kg), S433EA-AM701TS',\n",
       " '(Renewed) Dell Intel Core i7 4th Gen 14 Inch(35.56 cms) 1366x768 HD Laptop (16GB RAM /1TB SSD/Windows 10 Pro/MS Office 2019/Intel Integrated HD Graphics 4600/2.1Kg,Silver) Latitude E6440',\n",
       " 'Lenovo IdeaPad Flex 5 11th Gen Intel Core i7 14-inch FHD IPS 2-in-1 Touchscreen Laptop (16GB/512GB SSD/Win 10/Office 2019/Lenovo Digital Pen Stylus/Fingerprint Reader/Graphite Grey/1.5Kg), 82HS0092IN',\n",
       " 'Life Digital Laptop 15.6-inch (39.62 cms) (Intel Core i7, 4GB RAM, 256GB SSD, Windows 10), ZED AIR CX7',\n",
       " '(Renewed) Dell Intel Core i7 4th Gen 14 Inch(35.56 cms) 1366x768 HD Laptop (8GB RAM/256GB SSD/Windows 10 Pro/MS Office 2019/Intel Integrated HD Graphics 4600/2.1Kg,Silver) Latitude E6440',\n",
       " '(Renewed) Dell Intel Core i7 4th Gen 14 Inch(35.56 cms) 1366x768 HD Laptop (8GB RAM/1TB HDD/Windows 10 Pro/MS Office 2019/Intel Integrated HD Graphics 4600/2.1Kg,Silver) Latitude E6440',\n",
       " '(Renewed) Dell Latitude E7270 12.5 inch Laptop (Core i7 6th Gen/8 GB (Up to 16)/256 GB SSD/Windows 10 Pro/MS Office/HD Display/Integrated Graphics)',\n",
       " 'Lenovo ThinkPad E15 (2021) Intel Core i7 11th Gen 15.6\" FHD Thin and Light Laptop (16GB RAM/512GB SSD/Windows 10/MS Office/Fingerprint Reader/Black/Aluminium Surface/ 1.7 kg), 20TDS0G100',\n",
       " 'Dell Inspiron 5410 14\" FHD Touch Display 2in1 Laptop (i7-1165G7 / 16GB / 512GB SSD / Integrated Graphics / Win 10 + MSO / Backlit KB + FPR + Active Pen / Silver Metal Color) D560469WIN9S',\n",
       " 'MSI GE75 Raider 10SFS 17.3\" FHD Gaming Laptop - Core i7-10875H+HM470 I DDR IV 8GB*2 (3200MHz) I 512GB NVMe PCIe SSD +1TB (SATA) 7200rpm I NVIDIA RTX2070 Super, GDDR6 8GB I Windows 10 Home - Black',\n",
       " '(Renewed) Dell Intel Core i7 4th Gen 14 Inch(35.56 cms) 1366x768 HD Laptop (4GB RAM/320GB HDD/Windows 10 Pro/MS Office 2019/Intel Integrated HD Graphics 4600/2.1Kg,Silver) Latitude E6440',\n",
       " 'HP 14 Thin & Light 14\" (35.56cms) FHD Laptop (11th Gen Intel i7-1165G7/8GB/512GB SSD/Windows 10/MS Office 2019/Alexa Built-in/Pale Gold/1.47 kg), 14s-dr2007TU',\n",
       " 'MSI GF63 Thin 10SCSR-019IN Intel Core i7-10750H 10th Gen 15.6-inch 120Hz Laptop(8GB/512GB NVMe SSD /Windows 10 Home/Nvidia GeForce GTX 1650Ti Max-Q 4GB/Black/1.8Kg ) 9S7-16R412-019',\n",
       " 'Lenovo Legion Y540 9th Gen Intel Core i7 15.6-inch Full HD Gaming Laptop (8GB/1TB HDD + 256GB SSD/Windows 10/60 Hz/NVIDIA GTX 1650 4GB GDDR5 Graphics/Raven Black/2.3Kg), 81SY00SMIN',\n",
       " 'HP Pavilion Gaming(2021) 10th Gen Intel Core i7 15.6-inch(39.6 cm) FHD IPS 144Hz Gaming Laptop (16GB/512GB SSD + 32GB Intel Optane/NVIDIA GTX 1650Ti 4GB/Win 10/MS Office/Shadow Black), 15-DK1511TX']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scrape product name\n",
    "product_name=[]\n",
    "products=driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base a-text-normal']\")\n",
    "for i in products:\n",
    "    product_name.append(i.text)\n",
    "    \n",
    "product_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['84,990',\n",
       " '1,46,290',\n",
       " '86,990',\n",
       " '54,999',\n",
       " '96,089',\n",
       " '81,990',\n",
       " '76,990',\n",
       " '54,999',\n",
       " '2,59,990',\n",
       " '77,171',\n",
       " '49,999',\n",
       " '40,932',\n",
       " '42,999',\n",
       " '42,999',\n",
       " '49,999',\n",
       " '90,990',\n",
       " '85,490',\n",
       " '1,79,990',\n",
       " '39,999',\n",
       " '88,000',\n",
       " '84,990',\n",
       " '82,990',\n",
       " '90,990']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_title=[]\n",
    "price=driver.find_elements_by_xpath(\"//span[@class='a-price-whole']\")\n",
    "for i in price:\n",
    "    price_title.append(i.text)\n",
    "    \n",
    "price_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product name</th>\n",
       "      <th>price tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HP Pavilion (2021) Thin &amp; Light 11th Gen Core ...</td>\n",
       "      <td>84,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASUS ROG Zephyrus M15 (2020), 15.6\" 4K UHD, In...</td>\n",
       "      <td>1,46,290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HP Pavilion Gaming 10th Gen Intel Core i7 Proc...</td>\n",
       "      <td>86,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Renewed) Dell Intel Core i7 4th Gen 14 Inch(3...</td>\n",
       "      <td>54,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lenovo Yoga 7 11th Gen Intel Core i7 14\" (35.5...</td>\n",
       "      <td>96,089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ASUS TUF Gaming F15, 15.6\" FHD 144Hz, Intel Co...</td>\n",
       "      <td>81,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HP Pavilion x360 (2021) 14\" (35.56cms) FHD Tou...</td>\n",
       "      <td>76,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i5-1...</td>\n",
       "      <td>54,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ASUS ROG Zephyrus Duo 15, 15.6\" 4K UHD, Intel ...</td>\n",
       "      <td>2,59,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ASUS VivoBook S S14 Intel Core i7-1165G7 11th ...</td>\n",
       "      <td>77,171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Product name price tag\n",
       "0  HP Pavilion (2021) Thin & Light 11th Gen Core ...    84,990\n",
       "1  ASUS ROG Zephyrus M15 (2020), 15.6\" 4K UHD, In...  1,46,290\n",
       "2  HP Pavilion Gaming 10th Gen Intel Core i7 Proc...    86,990\n",
       "3  (Renewed) Dell Intel Core i7 4th Gen 14 Inch(3...    54,999\n",
       "4  Lenovo Yoga 7 11th Gen Intel Core i7 14\" (35.5...    96,089\n",
       "5  ASUS TUF Gaming F15, 15.6\" FHD 144Hz, Intel Co...    81,990\n",
       "6  HP Pavilion x360 (2021) 14\" (35.56cms) FHD Tou...    76,990\n",
       "7  Mi Notebook Horizon Edition 14 Intel Core i5-1...    54,999\n",
       "8  ASUS ROG Zephyrus Duo 15, 15.6\" 4K UHD, Intel ...  2,59,990\n",
       "9  ASUS VivoBook S S14 Intel Core i7-1165G7 11th ...    77,171"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "product=pd.DataFrame({})\n",
    "\n",
    "product['Product name']=product_name[:10]\n",
    "product['price tag']=price_title[:10]\n",
    "\n",
    "product\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
